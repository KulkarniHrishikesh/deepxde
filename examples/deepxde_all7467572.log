==========================================
SLURM_CLUSTER_NAME = param-brahma
SLURM_ARRAY_JOB_ID = 
SLURM_ARRAY_TASK_ID = 
SLURM_ARRAY_TASK_COUNT = 
SLURM_ARRAY_TASK_MAX = 
SLURM_ARRAY_TASK_MIN = 
SLURM_JOB_ACCOUNT = apte
SLURM_JOB_ID = 7467572
SLURM_JOB_NAME = deepXde_all
SLURM_JOB_NODELIST = gpu010
SLURM_JOB_USER = hrishikeshnk
SLURM_JOB_UID = 7324
SLURM_JOB_PARTITION = gpu
SLURM_TASK_PID = 33671
SLURM_SUBMIT_DIR = /home/hrishikeshnk/github.copy/deepxde/examples
SLURM_CPUS_ON_NODE = 1
SLURM_NTASKS = 
SLURM_TASK_PID = 33671
==========================================
ERROR: This cross-compiler package contains no program /home/apps/DL-Conda-Py3.7/bin/x86_64-conda_cos6-linux-gnu-ld
ERROR: deactivate-binutils_linux-64.sh failed, see above for details
ERROR: This cross-compiler package contains no program /home/apps/DL-Conda-Py3.7/bin/x86_64-conda_cos6-linux-gnu-ld
ERROR: activate-binutils_linux-64.sh failed, see above for details
Thu Jul 18 13:20:42 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-16GB           Off |   00000000:60:00.0 Off |                    0 |
| N/A   45C    P0             62W /  300W |       0MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Tesla V100-SXM2-16GB           Off |   00000000:61:00.0 Off |                    0 |
| N/A   46C    P0             59W /  300W |       0MiB /  16384MiB |      1%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
ERROR: This cross-compiler package contains no program /home/apps/DL-Conda-Py3.7/bin/x86_64-conda_cos6-linux-gnu-ld
ERROR: deactivate-binutils_linux-64.sh failed, see above for details

     active environment : deepxde
    active env location : /home/hrishikeshnk/.conda/envs/deepxde
            shell level : 2
       user config file : /home/hrishikeshnk/.condarc
 populated config files : 
          conda version : 22.11.1
    conda-build version : not installed
         python version : 3.7.7.final.0
       virtual packages : __archspec=1=x86_64
                          __cuda=12.4=0
                          __glibc=2.17=0
                          __linux=3.10.0=0
                          __unix=0=0
       base environment : /home/apps/DL-Conda-Py3.7  (read only)
      conda av data dir : /home/apps/DL-Conda-Py3.7/etc/conda
  conda av metadata url : None
           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/r/linux-64
                          https://repo.anaconda.com/pkgs/r/noarch
          package cache : /home/apps/DL-Conda-Py3.7/pkgs
                          /home/hrishikeshnk/.conda/pkgs
       envs directories : /home/hrishikeshnk/.conda/envs
                          /home/apps/DL-Conda-Py3.7/envs
               platform : linux-64
             user-agent : conda/22.11.1 requests/2.31.0 CPython/3.7.7 Linux/3.10.0-957.el7.x86_64 centos/7.6.1810 glibc/2.17
                UID:GID : 7324:7324
             netrc file : None
           offline mode : False

Using backend: pytorch

Compiling model...
'compile' took 0.000235 s

Training model...

Step      Train loss    Test loss     Test metric
0         [8.37e-01]    [8.37e-01]    []  
1000      [5.17e-02]    [5.17e-02]    []  
2000      [1.82e-02]    [1.82e-02]    []  
3000      [1.43e-02]    [1.43e-02]    []  
4000      [1.23e-02]    [1.23e-02]    []  
5000      [1.01e-02]    [1.01e-02]    []  
6000      [8.74e-03]    [8.74e-03]    []  
7000      [7.82e-03]    [7.82e-03]    []  
8000      [7.18e-03]    [7.18e-03]    []  
9000      [6.75e-03]    [6.75e-03]    []  
10000     [6.45e-03]    [6.45e-03]    []  
11000     [6.61e-03]    [6.61e-03]    []  
12000     [6.07e-03]    [6.07e-03]    []  
13000     [5.92e-03]    [5.92e-03]    []  
14000     [5.79e-03]    [5.79e-03]    []  
15000     [5.86e-03]    [5.86e-03]    []  
16000     [5.29e-03]    [5.29e-03]    []  
17000     [5.05e-03]    [5.05e-03]    []  
18000     [4.91e-03]    [4.91e-03]    []  
19000     [4.81e-03]    [4.81e-03]    []  
20000     [4.74e-03]    [4.74e-03]    []  
21000     [4.69e-03]    [4.69e-03]    []  
22000     [4.63e-03]    [4.63e-03]    []  
23000     [4.58e-03]    [4.58e-03]    []  
24000     [4.54e-03]    [4.54e-03]    []  
25000     [4.49e-03]    [4.49e-03]    []  
26000     [4.46e-03]    [4.46e-03]    []  
27000     [4.44e-03]    [4.44e-03]    []  
28000     [4.35e-03]    [4.35e-03]    []  
29000     [4.27e-03]    [4.27e-03]    []  
30000     [4.13e-03]    [4.13e-03]    []  
31000     [3.29e-03]    [3.29e-03]    []  
32000     [1.81e-03]    [1.81e-03]    []  
33000     [1.48e-03]    [1.48e-03]    []  
34000     [1.24e-03]    [1.24e-03]    []  
35000     [1.04e-03]    [1.04e-03]    []  
36000     [8.96e-04]    [8.96e-04]    []  
37000     [7.92e-04]    [7.92e-04]    []  
38000     [7.14e-04]    [7.14e-04]    []  
39000     [6.51e-04]    [6.51e-04]    []  
40000     [1.35e-03]    [1.35e-03]    []  

Best model at step 39000:
  train loss: 6.51e-04
  test loss: 6.51e-04
  test metric: []

'train' took 290.447909 s

Compiling model...
'compile' took 0.000178 s

Training model...

Step      Train loss    Test loss     Test metric
40000     [1.35e-03]    [1.35e-03]    []  
41000     [1.30e-04]    [1.30e-04]    []  
42000     [6.25e-05]    [6.25e-05]    []  
43000     [4.13e-05]    [4.13e-05]    []  
44000     [3.18e-05]    [3.18e-05]    []  
45000     [2.49e-05]    [2.49e-05]    []  
46000     [1.97e-05]    [1.97e-05]    []  
47000     [1.65e-05]    [1.65e-05]    []  
48000     [1.44e-05]    [1.44e-05]    []  
49000     [1.44e-05]    [1.44e-05]    []  
50000     [1.44e-05]    [1.44e-05]    []  
51000     [1.44e-05]    [1.44e-05]    []  
52000     [1.43e-05]    [1.43e-05]    []  
53000     [1.43e-05]    [1.43e-05]    []  
54000     [1.43e-05]    [1.43e-05]    []  
55000     [1.43e-05]    [1.43e-05]    []  

Best model at step 55000:
  train loss: 1.43e-05
  test loss: 1.43e-05
  test metric: []

'train' took 265.872595 s

Saving loss history to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/loss.dat ...
Saving training data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/train.dat ...
Saving test data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/test.dat ...
Mean residual: 0.0027668406
L2 relative error: 0.028283214345909354
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Allen_Cahn.py': No such file or directory
Using backend: pytorch

Warning: 283 points required, but 343 points sampled.
Warning: 10000 points required, but 12348 points sampled.
Compiling model...
'compile' took 0.000241 s

Training model...

Step      Train loss                                                                                              Test loss                                                                                               Test metric
0         [1.66e-01, 1.53e-01, 7.97e-02, 5.25e-02, 1.33e+02, 1.58e+02, 1.01e+02, 2.30e+02, 2.59e+02, 1.98e+02]    [1.74e-01, 1.67e-01, 8.63e-02, 5.86e-02, 1.33e+02, 1.58e+02, 1.01e+02, 2.30e+02, 2.59e+02, 1.98e+02]    []  
1000      [4.19e-01, 3.88e-01, 3.21e-01, 2.09e-02, 3.30e-01, 2.81e-01, 2.80e-01, 1.43e-01, 1.38e-01, 1.33e-01]    [1.19e-01, 1.26e-01, 1.38e-01, 1.09e-02, 3.30e-01, 2.81e-01, 2.80e-01, 1.43e-01, 1.38e-01, 1.33e-01]    []  
2000      [1.15e-01, 1.20e-01, 9.66e-02, 9.23e-03, 6.71e-02, 6.74e-02, 6.31e-02, 3.60e-02, 3.72e-02, 2.92e-02]    [3.78e-02, 3.61e-02, 4.02e-02, 5.10e-03, 6.71e-02, 6.74e-02, 6.31e-02, 3.60e-02, 3.72e-02, 2.92e-02]    []  
3000      [5.74e-02, 5.65e-02, 4.42e-02, 5.06e-03, 6.53e-02, 3.23e-02, 3.33e-02, 5.18e-02, 1.86e-02, 1.77e-02]    [1.99e-02, 1.79e-02, 1.80e-02, 2.61e-03, 6.53e-02, 3.23e-02, 3.33e-02, 5.18e-02, 1.86e-02, 1.77e-02]    []  
4000      [3.33e-02, 3.57e-02, 2.85e-02, 3.23e-03, 7.86e-02, 7.98e-02, 1.86e-02, 6.50e-02, 5.93e-02, 1.06e-02]    [1.23e-02, 1.30e-02, 1.28e-02, 1.55e-03, 7.86e-02, 7.98e-02, 1.86e-02, 6.50e-02, 5.93e-02, 1.06e-02]    []  
5000      [2.12e-02, 2.40e-02, 1.91e-02, 2.47e-03, 1.22e-02, 1.38e-02, 1.02e-02, 8.35e-03, 7.15e-03, 5.76e-03]    [7.18e-03, 8.89e-03, 8.26e-03, 1.29e-03, 1.22e-02, 1.38e-02, 1.02e-02, 8.35e-03, 7.15e-03, 5.76e-03]    []  
6000      [1.54e-02, 1.73e-02, 1.44e-02, 2.08e-03, 8.25e-03, 1.01e-02, 7.11e-03, 5.57e-03, 4.76e-03, 4.01e-03]    [5.17e-03, 6.42e-03, 6.21e-03, 1.17e-03, 8.25e-03, 1.01e-02, 7.11e-03, 5.57e-03, 4.76e-03, 4.01e-03]    []  
7000      [1.23e-02, 1.31e-02, 1.14e-02, 1.87e-03, 8.19e-03, 9.04e-03, 1.32e-02, 6.18e-03, 4.20e-03, 9.91e-03]    [4.18e-03, 5.01e-03, 4.85e-03, 1.13e-03, 8.19e-03, 9.04e-03, 1.32e-02, 6.18e-03, 4.20e-03, 9.91e-03]    []  
8000      [9.84e-03, 1.03e-02, 9.42e-03, 1.68e-03, 5.54e-03, 7.17e-03, 5.31e-03, 3.80e-03, 3.38e-03, 3.45e-03]    [3.38e-03, 3.92e-03, 3.97e-03, 1.03e-03, 5.54e-03, 7.17e-03, 5.31e-03, 3.80e-03, 3.38e-03, 3.45e-03]    []  
9000      [9.53e-03, 9.42e-03, 8.51e-03, 1.51e-03, 4.24e-02, 4.06e-02, 4.91e-02, 3.68e-02, 3.64e-02, 3.97e-02]    [3.97e-03, 3.81e-03, 3.85e-03, 8.91e-04, 4.24e-02, 4.06e-02, 4.91e-02, 3.68e-02, 3.64e-02, 3.97e-02]    []  
10000     [6.98e-03, 7.10e-03, 7.12e-03, 1.41e-03, 3.79e-03, 5.52e-03, 3.46e-03, 2.68e-03, 2.82e-03, 2.22e-03]    [2.58e-03, 2.76e-03, 2.96e-03, 8.69e-04, 3.79e-03, 5.52e-03, 3.46e-03, 2.68e-03, 2.82e-03, 2.22e-03]    []  
11000     [6.16e-03, 6.38e-03, 6.57e-03, 1.31e-03, 7.24e-03, 2.04e-02, 6.47e-03, 6.00e-03, 1.84e-02, 4.62e-03]    [2.38e-03, 2.55e-03, 2.89e-03, 7.79e-04, 7.24e-03, 2.04e-02, 6.47e-03, 6.00e-03, 1.84e-02, 4.62e-03]    []  
12000     [5.26e-03, 5.46e-03, 5.76e-03, 1.21e-03, 2.84e-03, 3.21e-03, 2.77e-03, 2.08e-03, 1.49e-03, 1.82e-03]    [2.08e-03, 2.14e-03, 2.47e-03, 7.27e-04, 2.84e-03, 3.21e-03, 2.77e-03, 2.08e-03, 1.49e-03, 1.82e-03]    []  
13000     [4.71e-03, 5.00e-03, 5.31e-03, 1.13e-03, 1.00e-02, 2.95e-03, 5.13e-03, 8.29e-03, 1.52e-03, 4.12e-03]    [1.89e-03, 2.03e-03, 2.27e-03, 6.80e-04, 1.00e-02, 2.95e-03, 5.13e-03, 8.29e-03, 1.52e-03, 4.12e-03]    []  
14000     [4.41e-03, 4.65e-03, 5.20e-03, 1.07e-03, 8.74e-03, 1.17e-02, 1.59e-02, 9.32e-03, 1.01e-02, 1.37e-02]    [2.08e-03, 1.91e-03, 2.45e-03, 6.07e-04, 8.74e-03, 1.17e-02, 1.59e-02, 9.32e-03, 1.01e-02, 1.37e-02]    []  
15000     [3.81e-03, 4.17e-03, 4.55e-03, 9.96e-04, 2.04e-03, 2.42e-03, 2.24e-03, 1.56e-03, 1.29e-03, 1.51e-03]    [1.69e-03, 1.68e-03, 2.02e-03, 5.68e-04, 2.04e-03, 2.42e-03, 2.24e-03, 1.56e-03, 1.29e-03, 1.51e-03]    []  
16000     [3.54e-03, 3.94e-03, 4.26e-03, 9.40e-04, 3.73e-03, 2.42e-03, 2.01e-03, 3.42e-03, 1.27e-03, 1.38e-03]    [1.65e-03, 1.63e-03, 1.90e-03, 5.34e-04, 3.73e-03, 2.42e-03, 2.01e-03, 3.42e-03, 1.27e-03, 1.38e-03]    []  
17000     [3.31e-03, 3.71e-03, 4.00e-03, 8.99e-04, 1.87e-03, 2.54e-03, 2.03e-03, 1.41e-03, 1.38e-03, 1.40e-03]    [1.53e-03, 1.52e-03, 1.78e-03, 5.01e-04, 1.87e-03, 2.54e-03, 2.03e-03, 1.41e-03, 1.38e-03, 1.40e-03]    []  
18000     [3.10e-03, 3.52e-03, 3.78e-03, 8.49e-04, 2.05e-03, 3.55e-03, 2.13e-03, 1.75e-03, 2.69e-03, 1.47e-03]    [1.48e-03, 1.48e-03, 1.73e-03, 4.67e-04, 2.05e-03, 3.55e-03, 2.13e-03, 1.75e-03, 2.69e-03, 1.47e-03]    []  
19000     [3.35e-03, 3.51e-03, 3.80e-03, 8.13e-04, 4.73e-03, 1.58e-02, 1.53e-02, 4.16e-03, 1.40e-02, 1.34e-02]    [1.84e-03, 1.52e-03, 1.80e-03, 4.55e-04, 4.73e-03, 1.58e-02, 1.53e-02, 4.16e-03, 1.40e-02, 1.34e-02]    []  
20000     [2.76e-03, 3.22e-03, 3.35e-03, 7.78e-04, 1.33e-03, 1.61e-03, 1.51e-03, 1.01e-03, 8.41e-04, 9.87e-04]    [1.33e-03, 1.37e-03, 1.51e-03, 4.40e-04, 1.33e-03, 1.61e-03, 1.51e-03, 1.01e-03, 8.41e-04, 9.87e-04]    []  
21000     [2.63e-03, 3.09e-03, 3.16e-03, 7.38e-04, 2.56e-03, 1.64e-03, 2.67e-03, 2.17e-03, 9.11e-04, 2.13e-03]    [1.27e-03, 1.33e-03, 1.38e-03, 4.12e-04, 2.56e-03, 1.64e-03, 2.67e-03, 2.17e-03, 9.11e-04, 2.13e-03]    []  
22000     [2.50e-03, 2.97e-03, 2.99e-03, 7.10e-04, 2.28e-03, 1.54e-03, 1.64e-03, 1.96e-03, 8.61e-04, 1.09e-03]    [1.25e-03, 1.27e-03, 1.33e-03, 3.94e-04, 2.28e-03, 1.54e-03, 1.64e-03, 1.96e-03, 8.61e-04, 1.09e-03]    []  
23000     [2.57e-03, 3.05e-03, 3.18e-03, 6.96e-04, 3.11e-03, 1.45e-02, 1.76e-03, 2.72e-03, 1.32e-02, 1.15e-03]    [1.32e-03, 1.41e-03, 1.49e-03, 3.77e-04, 3.11e-03, 1.45e-02, 1.76e-03, 2.72e-03, 1.32e-02, 1.15e-03]    []  
24000     [2.33e-03, 2.83e-03, 2.77e-03, 6.62e-04, 1.23e-03, 1.63e-03, 1.43e-03, 8.96e-04, 9.08e-04, 9.86e-04]    [1.15e-03, 1.23e-03, 1.17e-03, 3.71e-04, 1.23e-03, 1.63e-03, 1.43e-03, 8.96e-04, 9.08e-04, 9.86e-04]    []  
25000     [3.37e-03, 3.20e-03, 3.03e-03, 6.37e-04, 2.05e-03, 1.46e-02, 6.04e-02, 1.67e-03, 1.32e-02, 5.35e-02]    [2.06e-03, 1.42e-03, 1.46e-03, 3.32e-04, 2.05e-03, 1.46e-02, 6.04e-02, 1.67e-03, 1.32e-02, 5.35e-02]    []  
26000     [2.57e-03, 3.49e-03, 2.72e-03, 6.15e-04, 6.76e-02, 2.09e-03, 3.17e-03, 6.49e-02, 1.51e-03, 2.40e-03]    [1.26e-03, 1.89e-03, 1.19e-03, 3.47e-04, 6.76e-02, 2.09e-03, 3.17e-03, 6.49e-02, 1.51e-03, 2.40e-03]    []  
27000     [2.10e-03, 2.62e-03, 2.45e-03, 6.08e-04, 9.56e-04, 1.24e-03, 1.07e-03, 6.43e-04, 6.47e-04, 6.65e-04]    [1.07e-03, 1.14e-03, 1.03e-03, 3.49e-04, 9.56e-04, 1.24e-03, 1.07e-03, 6.43e-04, 6.47e-04, 6.65e-04]    []  
28000     [2.02e-03, 2.52e-03, 2.34e-03, 5.79e-04, 9.18e-04, 1.14e-03, 1.01e-03, 6.10e-04, 6.05e-04, 6.23e-04]    [1.03e-03, 1.10e-03, 9.79e-04, 3.28e-04, 9.18e-04, 1.14e-03, 1.01e-03, 6.10e-04, 6.05e-04, 6.23e-04]    []  
29000     [1.97e-03, 2.49e-03, 2.40e-03, 5.61e-04, 2.11e-03, 1.20e-02, 1.37e-03, 1.79e-03, 1.09e-02, 9.52e-04]    [1.00e-03, 1.12e-03, 1.02e-03, 3.28e-04, 2.11e-03, 1.20e-02, 1.37e-03, 1.79e-03, 1.09e-02, 9.52e-04]    []  
30000     [1.88e-03, 2.38e-03, 2.16e-03, 5.33e-04, 8.55e-04, 1.05e-03, 9.45e-04, 5.53e-04, 5.49e-04, 5.86e-04]    [9.60e-04, 1.05e-03, 8.90e-04, 3.01e-04, 8.55e-04, 1.05e-03, 9.45e-04, 5.53e-04, 5.49e-04, 5.86e-04]    []  

Best model at step 30000:
  train loss: 1.15e-02
  test loss: 7.73e-03
  test metric: []

'train' took 2611.307353 s

Compiling model...
'compile' took 0.000194 s

Training model...

Step      Train loss                                                                                              Test loss                                                                                               Test metric
30000     [1.88e-03, 2.38e-03, 2.16e-03, 5.33e-04, 8.55e-04, 1.05e-03, 9.45e-04, 5.53e-04, 5.49e-04, 5.86e-04]    [9.60e-04, 1.05e-03, 8.90e-04, 3.01e-04, 8.55e-04, 1.05e-03, 9.45e-04, 5.53e-04, 5.49e-04, 5.86e-04]    []  
31000     [4.19e-04, 5.01e-04, 4.04e-04, 1.10e-04, 2.01e-04, 1.96e-04, 2.17e-04, 9.40e-05, 9.86e-05, 1.37e-04]    [1.75e-04, 1.90e-04, 1.65e-04, 5.36e-05, 2.01e-04, 1.96e-04, 2.17e-04, 9.40e-05, 9.86e-05, 1.37e-04]    []  
32000     [1.78e-04, 2.47e-04, 2.15e-04, 6.19e-05, 9.49e-05, 1.05e-04, 1.33e-04, 4.82e-05, 5.26e-05, 5.50e-05]    [6.64e-05, 9.07e-05, 9.00e-05, 2.52e-05, 9.49e-05, 1.05e-04, 1.33e-04, 4.82e-05, 5.26e-05, 5.50e-05]    []  
33000     [1.14e-04, 1.45e-04, 1.28e-04, 4.13e-05, 5.64e-05, 6.60e-05, 8.37e-05, 3.41e-05, 3.17e-05, 3.64e-05]    [3.59e-05, 6.02e-05, 5.35e-05, 1.61e-05, 5.64e-05, 6.60e-05, 8.37e-05, 3.41e-05, 3.17e-05, 3.64e-05]    []  
34000     [8.88e-05, 9.69e-05, 8.57e-05, 2.91e-05, 4.77e-05, 4.34e-05, 6.17e-05, 2.38e-05, 2.12e-05, 2.58e-05]    [3.27e-05, 4.00e-05, 3.07e-05, 1.24e-05, 4.77e-05, 4.34e-05, 6.17e-05, 2.38e-05, 2.12e-05, 2.58e-05]    []  
35000     [6.93e-05, 6.97e-05, 6.65e-05, 2.68e-05, 3.61e-05, 3.61e-05, 4.53e-05, 1.73e-05, 1.65e-05, 1.86e-05]    [2.59e-05, 2.89e-05, 2.60e-05, 1.18e-05, 3.61e-05, 3.61e-05, 4.53e-05, 1.73e-05, 1.65e-05, 1.86e-05]    []  
36000     [5.36e-05, 5.33e-05, 5.48e-05, 2.15e-05, 2.98e-05, 2.83e-05, 3.75e-05, 1.51e-05, 1.33e-05, 1.73e-05]    [1.90e-05, 2.13e-05, 2.04e-05, 9.21e-06, 2.98e-05, 2.83e-05, 3.75e-05, 1.51e-05, 1.33e-05, 1.73e-05]    []  
37000     [4.67e-05, 4.43e-05, 4.72e-05, 1.68e-05, 2.49e-05, 2.38e-05, 3.05e-05, 1.30e-05, 1.25e-05, 1.32e-05]    [1.85e-05, 1.66e-05, 1.71e-05, 7.30e-06, 2.49e-05, 2.38e-05, 3.05e-05, 1.30e-05, 1.25e-05, 1.32e-05]    []  
38000     [4.05e-05, 3.84e-05, 3.70e-05, 1.46e-05, 2.13e-05, 2.10e-05, 2.64e-05, 1.05e-05, 1.12e-05, 1.20e-05]    [1.44e-05, 1.57e-05, 1.43e-05, 5.92e-06, 2.13e-05, 2.10e-05, 2.64e-05, 1.05e-05, 1.12e-05, 1.20e-05]    []  
39000     [3.73e-05, 3.32e-05, 3.20e-05, 1.27e-05, 1.88e-05, 1.94e-05, 2.25e-05, 9.07e-06, 9.26e-06, 1.02e-05]    [1.43e-05, 1.33e-05, 1.26e-05, 4.92e-06, 1.88e-05, 1.94e-05, 2.25e-05, 9.07e-06, 9.26e-06, 1.02e-05]    []  
40000     [3.32e-05, 2.90e-05, 2.68e-05, 1.12e-05, 1.60e-05, 1.72e-05, 1.89e-05, 8.51e-06, 8.46e-06, 9.41e-06]    [1.18e-05, 1.12e-05, 1.15e-05, 4.83e-06, 1.60e-05, 1.72e-05, 1.89e-05, 8.51e-06, 8.46e-06, 9.41e-06]    []  
41000     [3.02e-05, 2.62e-05, 2.43e-05, 1.04e-05, 1.44e-05, 1.49e-05, 1.63e-05, 7.56e-06, 7.44e-06, 7.98e-06]    [9.73e-06, 9.87e-06, 1.03e-05, 4.61e-06, 1.44e-05, 1.49e-05, 1.63e-05, 7.56e-06, 7.44e-06, 7.98e-06]    []  
42000     [2.82e-05, 2.33e-05, 2.23e-05, 9.02e-06, 1.28e-05, 1.38e-05, 1.39e-05, 7.09e-06, 6.48e-06, 6.82e-06]    [9.52e-06, 9.21e-06, 9.04e-06, 3.75e-06, 1.28e-05, 1.38e-05, 1.39e-05, 7.09e-06, 6.48e-06, 6.82e-06]    []  
43000     [2.64e-05, 2.11e-05, 1.99e-05, 8.31e-06, 1.15e-05, 1.26e-05, 1.24e-05, 6.79e-06, 6.01e-06, 5.98e-06]    [9.21e-06, 8.59e-06, 8.28e-06, 3.69e-06, 1.15e-05, 1.26e-05, 1.24e-05, 6.79e-06, 6.01e-06, 5.98e-06]    []  
44000     [2.55e-05, 1.93e-05, 1.82e-05, 7.59e-06, 9.98e-06, 1.17e-05, 1.09e-05, 5.47e-06, 5.46e-06, 5.51e-06]    [9.35e-06, 8.15e-06, 7.16e-06, 3.29e-06, 9.98e-06, 1.17e-05, 1.09e-05, 5.47e-06, 5.46e-06, 5.51e-06]    []  
45000     [2.46e-05, 1.78e-05, 1.66e-05, 6.91e-06, 9.00e-06, 1.02e-05, 9.71e-06, 4.70e-06, 5.22e-06, 5.27e-06]    [9.03e-06, 8.09e-06, 6.71e-06, 3.22e-06, 9.00e-06, 1.02e-05, 9.71e-06, 4.70e-06, 5.22e-06, 5.27e-06]    []  

Best model at step 45000:
  train loss: 1.10e-04
  test loss: 7.12e-05
  test metric: []

'train' took 1464.883503 s

Accuracy at t = 0:
Mean residual: 0.00712148
L2 relative error in u: 0.00033915750569565834
L2 relative error in v: 0.00035838003399874815
L2 relative error in w: 0.0003211509241825341


Accuracy at t = 1:
Mean residual: 0.0038698176
L2 relative error in u: 0.0010152710404007991
L2 relative error in v: 0.0010526357898923487
L2 relative error in w: 0.0013135686576778516
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Beltrami_flow.py': No such file or directory
Using backend: pytorch

Compiling model...
'compile' took 0.000155 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [8.63e-03, 2.16e-02, 6.07e-01]    [8.63e-03, 2.16e-02, 6.07e-01]    []  
1000      [3.91e-02, 8.17e-04, 5.68e-02]    [3.91e-02, 8.17e-04, 5.68e-02]    []  
2000      [3.10e-02, 3.21e-05, 4.36e-02]    [3.10e-02, 3.21e-05, 4.36e-02]    []  
3000      [1.32e-02, 1.01e-04, 8.49e-03]    [1.32e-02, 1.01e-04, 8.49e-03]    []  
4000      [4.20e-03, 2.35e-05, 4.43e-03]    [4.20e-03, 2.35e-05, 4.43e-03]    []  
5000      [2.72e-03, 1.59e-05, 2.91e-03]    [2.72e-03, 1.59e-05, 2.91e-03]    []  
6000      [2.24e-03, 1.20e-05, 2.40e-03]    [2.24e-03, 1.20e-05, 2.40e-03]    []  
7000      [1.99e-03, 7.48e-06, 2.17e-03]    [1.99e-03, 7.48e-06, 2.17e-03]    []  
8000      [1.82e-03, 9.70e-06, 2.00e-03]    [1.82e-03, 9.70e-06, 2.00e-03]    []  
9000      [1.70e-03, 5.24e-06, 1.84e-03]    [1.70e-03, 5.24e-06, 1.84e-03]    []  
10000     [1.63e-03, 4.18e-06, 1.69e-03]    [1.63e-03, 4.18e-06, 1.69e-03]    []  
11000     [1.31e-03, 4.52e-06, 1.28e-03]    [1.31e-03, 4.52e-06, 1.28e-03]    []  
12000     [1.17e-03, 4.03e-06, 1.19e-03]    [1.17e-03, 4.03e-06, 1.19e-03]    []  
13000     [1.07e-03, 3.53e-06, 1.12e-03]    [1.07e-03, 3.53e-06, 1.12e-03]    []  
14000     [1.00e-03, 3.09e-06, 1.05e-03]    [1.00e-03, 3.09e-06, 1.05e-03]    []  
15000     [1.18e-03, 3.49e-06, 1.03e-03]    [1.18e-03, 3.49e-06, 1.03e-03]    []  

Best model at step 14000:
  train loss: 2.06e-03
  test loss: 2.06e-03
  test metric: []

'train' took 65.291068 s

Compiling model...
'compile' took 0.000182 s

Training model...

Step      Train loss                        Test loss                         Test metric
15000     [1.18e-03, 3.49e-06, 1.03e-03]    [1.18e-03, 3.49e-06, 1.03e-03]    []  
16000     [2.19e-04, 1.78e-06, 1.13e-04]    [2.19e-04, 1.78e-06, 1.13e-04]    []  
17000     [8.36e-05, 4.82e-07, 4.67e-05]    [8.36e-05, 4.82e-07, 4.67e-05]    []  
18000     [5.31e-05, 2.37e-07, 2.41e-05]    [5.31e-05, 2.37e-07, 2.41e-05]    []  
19000     [3.81e-05, 1.16e-07, 1.09e-05]    [3.81e-05, 1.16e-07, 1.09e-05]    []  
20000     [2.59e-05, 1.28e-07, 4.92e-06]    [2.59e-05, 1.28e-07, 4.92e-06]    []  
21000     [1.77e-05, 9.33e-08, 1.85e-06]    [1.77e-05, 9.33e-08, 1.85e-06]    []  
22000     [1.22e-05, 9.88e-08, 8.38e-07]    [1.22e-05, 9.88e-08, 8.38e-07]    []  
23000     [8.61e-06, 5.60e-08, 6.87e-07]    [8.61e-06, 5.60e-08, 6.87e-07]    []  
24000     [6.33e-06, 2.82e-08, 4.10e-07]    [6.33e-06, 2.82e-08, 4.10e-07]    []  
25000     [5.51e-06, 4.61e-08, 2.27e-07]    [5.51e-06, 4.61e-08, 2.27e-07]    []  
26000     [5.49e-06, 4.61e-08, 2.25e-07]    [5.49e-06, 4.61e-08, 2.25e-07]    []  
27000     [5.48e-06, 4.59e-08, 2.23e-07]    [5.48e-06, 4.59e-08, 2.23e-07]    []  
28000     [5.47e-06, 4.57e-08, 2.22e-07]    [5.47e-06, 4.57e-08, 2.22e-07]    []  
29000     [5.46e-06, 4.55e-08, 2.21e-07]    [5.46e-06, 4.55e-08, 2.21e-07]    []  
30000     [5.45e-06, 4.53e-08, 2.20e-07]    [5.45e-06, 4.53e-08, 2.20e-07]    []  

Best model at step 30000:
  train loss: 5.72e-06
  test loss: 5.72e-06
  test metric: []

'train' took 210.272548 s

Saving loss history to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/loss.dat ...
Saving training data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/train.dat ...
Saving test data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/test.dat ...
Mean residual: 0.0029492865
L2 relative error: 0.0026181652899180774
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Burgers.py': No such file or directory
Using backend: pytorch

Compiling model...
'compile' took 0.000153 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.20e-02, 1.69e-02, 4.42e-01]    [2.20e-02, 1.69e-02, 4.42e-01]    []  
1000      [3.60e-02, 1.79e-04, 5.04e-02]    [3.60e-02, 1.79e-04, 5.04e-02]    []  
2000      [2.45e-02, 3.24e-05, 3.43e-02]    [2.45e-02, 3.24e-05, 3.43e-02]    []  
3000      [5.03e-03, 1.95e-05, 4.67e-03]    [5.03e-03, 1.95e-05, 4.67e-03]    []  
4000      [3.07e-03, 1.38e-05, 2.87e-03]    [3.07e-03, 1.38e-05, 2.87e-03]    []  
5000      [1.82e-03, 1.21e-05, 2.22e-03]    [1.82e-03, 1.21e-05, 2.22e-03]    []  
6000      [1.46e-03, 8.30e-06, 1.80e-03]    [1.46e-03, 8.30e-06, 1.80e-03]    []  
7000      [1.28e-03, 6.21e-06, 1.42e-03]    [1.28e-03, 6.21e-06, 1.42e-03]    []  
8000      [9.71e-04, 4.33e-06, 9.44e-04]    [9.71e-04, 4.33e-06, 9.44e-04]    []  
9000      [8.14e-04, 3.37e-06, 7.74e-04]    [8.14e-04, 3.37e-06, 7.74e-04]    []  
10000     [6.98e-04, 2.94e-06, 6.50e-04]    [6.98e-04, 2.94e-06, 6.50e-04]    []  

Best model at step 10000:
  train loss: 1.35e-03
  test loss: 1.35e-03
  test metric: []

'train' took 43.903931 s

Compiling model...
'compile' took 0.000176 s

Training model...

Step      Train loss                        Test loss                         Test metric
10000     [6.98e-04, 2.94e-06, 6.50e-04]    [6.98e-04, 2.94e-06, 6.50e-04]    []  
11000     [7.00e-04, 2.88e-06, 6.47e-04]    [7.00e-04, 2.88e-06, 6.47e-04]    []  
12000     [7.00e-04, 2.84e-06, 6.45e-04]    [7.00e-04, 2.84e-06, 6.45e-04]    []  
13000     [6.99e-04, 2.83e-06, 6.44e-04]    [6.99e-04, 2.83e-06, 6.44e-04]    []  
14000     [6.98e-04, 2.82e-06, 6.44e-04]    [6.98e-04, 2.82e-06, 6.44e-04]    []  
15000     [6.97e-04, 2.81e-06, 6.43e-04]    [6.97e-04, 2.81e-06, 6.43e-04]    []  
16000     [6.97e-04, 2.81e-06, 6.42e-04]    [6.97e-04, 2.81e-06, 6.42e-04]    []  
17000     [6.96e-04, 2.80e-06, 6.41e-04]    [6.96e-04, 2.80e-06, 6.41e-04]    []  
18000     [6.95e-04, 2.79e-06, 6.41e-04]    [6.95e-04, 2.79e-06, 6.41e-04]    []  
19000     [6.95e-04, 2.78e-06, 6.40e-04]    [6.95e-04, 2.78e-06, 6.40e-04]    []  
20000     [6.94e-04, 2.77e-06, 6.39e-04]    [6.94e-04, 2.77e-06, 6.39e-04]    []  
21000     [6.94e-04, 2.76e-06, 6.39e-04]    [6.94e-04, 2.76e-06, 6.39e-04]    []  
22000     [6.93e-04, 2.76e-06, 6.38e-04]    [6.93e-04, 2.76e-06, 6.38e-04]    []  
23000     [6.92e-04, 2.75e-06, 6.37e-04]    [6.92e-04, 2.75e-06, 6.37e-04]    []  
24000     [6.92e-04, 2.74e-06, 6.36e-04]    [6.92e-04, 2.74e-06, 6.36e-04]    []  
25000     [6.91e-04, 2.73e-06, 6.36e-04]    [6.91e-04, 2.73e-06, 6.36e-04]    []  

Best model at step 25000:
  train loss: 1.33e-03
  test loss: 1.33e-03
  test metric: []

'train' took 66.391705 s

Mean residual: 1.747e-02
Adding new point: [-0.00156665  0.98035085] 

Compiling model...
'compile' took 0.000145 s

Training model...

Step      Train loss                        Test loss                         Test metric
25000     [1.72e-03, 2.73e-06, 6.36e-04]    [6.91e-04, 2.73e-06, 6.36e-04]    []  
26000     [7.13e-04, 2.62e-06, 5.93e-04]    [7.06e-04, 2.62e-06, 5.93e-04]    []  
27000     [6.21e-04, 2.65e-06, 5.18e-04]    [6.19e-04, 2.65e-06, 5.18e-04]    []  
28000     [7.05e-04, 1.69e-06, 4.63e-04]    [7.05e-04, 1.69e-06, 4.63e-04]    []  
29000     [4.91e-04, 2.33e-06, 3.91e-04]    [4.91e-04, 2.33e-06, 3.91e-04]    []  
30000     [4.38e-04, 2.23e-06, 3.38e-04]    [4.38e-04, 2.23e-06, 3.38e-04]    []  
31000     [3.89e-04, 1.96e-06, 2.93e-04]    [3.89e-04, 1.96e-06, 2.93e-04]    []  
32000     [3.80e-04, 2.56e-06, 2.49e-04]    [3.80e-04, 2.56e-06, 2.49e-04]    []  
33000     [1.17e-03, 2.78e-06, 2.30e-04]    [1.16e-03, 2.78e-06, 2.30e-04]    []  
34000     [2.78e-04, 1.70e-06, 1.95e-04]    [2.78e-04, 1.70e-06, 1.95e-04]    []  
35000     [2.53e-04, 1.60e-06, 1.74e-04]    [2.53e-04, 1.60e-06, 1.74e-04]    []  

Best model at step 35000:
  train loss: 4.29e-04
  test loss: 4.29e-04
  test metric: []

'train' took 44.147302 s

Compiling model...
'compile' took 0.000116 s

Training model...

Step      Train loss                        Test loss                         Test metric
35000     [2.53e-04, 1.60e-06, 1.74e-04]    [2.53e-04, 1.60e-06, 1.74e-04]    []  
36000     [2.54e-04, 1.58e-06, 1.74e-04]    [2.54e-04, 1.58e-06, 1.74e-04]    []  
37000     [2.53e-04, 1.58e-06, 1.74e-04]    [2.54e-04, 1.58e-06, 1.74e-04]    []  
38000     [2.53e-04, 1.58e-06, 1.74e-04]    [2.53e-04, 1.58e-06, 1.74e-04]    []  
39000     [2.53e-04, 1.57e-06, 1.74e-04]    [2.53e-04, 1.57e-06, 1.74e-04]    []  
40000     [2.53e-04, 1.57e-06, 1.74e-04]    [2.53e-04, 1.57e-06, 1.74e-04]    []  
41000     [2.53e-04, 1.57e-06, 1.74e-04]    [2.53e-04, 1.57e-06, 1.74e-04]    []  
42000     [2.53e-04, 1.57e-06, 1.74e-04]    [2.53e-04, 1.57e-06, 1.74e-04]    []  
43000     [2.53e-04, 1.57e-06, 1.74e-04]    [2.53e-04, 1.57e-06, 1.74e-04]    []  
44000     [2.53e-04, 1.57e-06, 1.74e-04]    [2.53e-04, 1.57e-06, 1.74e-04]    []  
45000     [2.53e-04, 1.56e-06, 1.74e-04]    [2.53e-04, 1.56e-06, 1.74e-04]    []  
46000     [2.53e-04, 1.56e-06, 1.74e-04]    [2.53e-04, 1.56e-06, 1.74e-04]    []  
47000     [2.53e-04, 1.56e-06, 1.74e-04]    [2.53e-04, 1.56e-06, 1.74e-04]    []  
48000     [2.53e-04, 1.56e-06, 1.74e-04]    [2.53e-04, 1.56e-06, 1.74e-04]    []  
49000     [2.53e-04, 1.56e-06, 1.74e-04]    [2.53e-04, 1.56e-06, 1.74e-04]    []  
50000     [2.52e-04, 1.55e-06, 1.74e-04]    [2.53e-04, 1.55e-06, 1.74e-04]    []  

Best model at step 50000:
  train loss: 4.28e-04
  test loss: 4.28e-04
  test metric: []

'train' took 66.420815 s

Mean residual: 1.150e-02
Adding new point: [0.00140965 0.49970552] 

Compiling model...
'compile' took 0.000138 s

Training model...

Step      Train loss                        Test loss                         Test metric
50000     [1.58e-03, 1.55e-06, 1.74e-04]    [2.53e-04, 1.55e-06, 1.74e-04]    []  
51000     [3.36e-04, 1.93e-06, 2.10e-04]    [3.16e-04, 1.93e-06, 2.10e-04]    []  
52000     [2.92e-04, 1.87e-06, 1.89e-04]    [2.84e-04, 1.87e-06, 1.89e-04]    []  
53000     [5.32e-04, 3.02e-06, 1.72e-04]    [5.00e-04, 3.02e-06, 1.72e-04]    []  
Epoch 53000: early stopping

Best model at step 52000:
  train loss: 4.83e-04
  test loss: 4.75e-04
  test metric: []

'train' took 13.260528 s

Compiling model...
'compile' took 0.000113 s

Training model...

Step      Train loss                        Test loss                         Test metric
53000     [5.32e-04, 3.02e-06, 1.72e-04]    [5.00e-04, 3.02e-06, 1.72e-04]    []  
54000     [8.86e-05, 4.48e-07, 5.61e-05]    [8.84e-05, 4.48e-07, 5.61e-05]    []  
55000     [4.50e-05, 1.90e-07, 1.96e-05]    [4.50e-05, 1.90e-07, 1.96e-05]    []  
56000     [2.95e-05, 1.05e-07, 7.24e-06]    [2.96e-05, 1.05e-07, 7.24e-06]    []  
57000     [1.85e-05, 1.31e-07, 1.83e-06]    [1.85e-05, 1.31e-07, 1.83e-06]    []  
58000     [1.09e-05, 5.56e-08, 7.21e-07]    [1.09e-05, 5.56e-08, 7.21e-07]    []  
59000     [7.27e-06, 1.96e-08, 4.64e-07]    [7.28e-06, 1.96e-08, 4.64e-07]    []  
60000     [5.19e-06, 2.91e-08, 3.67e-07]    [5.20e-06, 2.91e-08, 3.67e-07]    []  
61000     [5.00e-06, 2.63e-08, 3.66e-07]    [5.00e-06, 2.63e-08, 3.66e-07]    []  
62000     [5.00e-06, 2.57e-08, 3.66e-07]    [5.00e-06, 2.57e-08, 3.66e-07]    []  
63000     [4.99e-06, 2.54e-08, 3.66e-07]    [4.99e-06, 2.54e-08, 3.66e-07]    []  
64000     [4.99e-06, 2.52e-08, 3.66e-07]    [4.99e-06, 2.52e-08, 3.66e-07]    []  
65000     [4.99e-06, 2.50e-08, 3.67e-07]    [4.99e-06, 2.50e-08, 3.67e-07]    []  
66000     [4.98e-06, 2.49e-08, 3.67e-07]    [4.99e-06, 2.49e-08, 3.67e-07]    []  
67000     [4.98e-06, 2.48e-08, 3.68e-07]    [4.98e-06, 2.48e-08, 3.68e-07]    []  
68000     [4.98e-06, 2.47e-08, 3.68e-07]    [4.98e-06, 2.47e-08, 3.68e-07]    []  

Best model at step 68000:
  train loss: 5.37e-06
  test loss: 5.38e-06
  test metric: []

'train' took 213.414033 s

Mean residual: 4.389e-03
Adding new point: [0.00598717 0.38403732] 

Compiling model...
'compile' took 0.000681 s

Training model...

Step      Train loss                        Test loss                         Test metric
68000     [3.83e-03, 2.47e-08, 3.68e-07]    [4.98e-06, 2.47e-08, 3.68e-07]    []  
69000     [6.38e-05, 5.92e-08, 3.17e-05]    [6.17e-05, 5.92e-08, 3.17e-05]    []  
70000     [4.36e-05, 4.30e-08, 3.28e-05]    [4.26e-05, 4.30e-08, 3.28e-05]    []  
71000     [3.74e-05, 3.68e-08, 3.25e-05]    [3.68e-05, 3.68e-08, 3.25e-05]    []  
Epoch 71000: early stopping

Best model at step 71000:
  train loss: 7.00e-05
  test loss: 6.93e-05
  test metric: []

'train' took 13.251555 s

Compiling model...
'compile' took 0.000132 s

Training model...

Step      Train loss                        Test loss                         Test metric
71000     [3.74e-05, 3.68e-08, 3.25e-05]    [3.68e-05, 3.68e-08, 3.25e-05]    []  
72000     [3.74e-05, 3.63e-08, 3.25e-05]    [3.68e-05, 3.63e-08, 3.25e-05]    []  
73000     [3.74e-05, 3.63e-08, 3.25e-05]    [3.68e-05, 3.63e-08, 3.25e-05]    []  
74000     [3.74e-05, 3.62e-08, 3.25e-05]    [3.68e-05, 3.62e-08, 3.25e-05]    []  
75000     [3.74e-05, 3.61e-08, 3.24e-05]    [3.68e-05, 3.61e-08, 3.24e-05]    []  
76000     [3.74e-05, 3.59e-08, 3.24e-05]    [3.68e-05, 3.59e-08, 3.24e-05]    []  
77000     [3.74e-05, 3.58e-08, 3.24e-05]    [3.68e-05, 3.58e-08, 3.24e-05]    []  
78000     [3.74e-05, 3.56e-08, 3.24e-05]    [3.68e-05, 3.56e-08, 3.24e-05]    []  
79000     [3.74e-05, 3.55e-08, 3.24e-05]    [3.68e-05, 3.55e-08, 3.24e-05]    []  
80000     [3.74e-05, 3.54e-08, 3.24e-05]    [3.68e-05, 3.54e-08, 3.24e-05]    []  
81000     [3.74e-05, 3.53e-08, 3.24e-05]    [3.68e-05, 3.53e-08, 3.24e-05]    []  
82000     [3.74e-05, 3.53e-08, 3.24e-05]    [3.68e-05, 3.53e-08, 3.24e-05]    []  
83000     [3.73e-05, 3.52e-08, 3.24e-05]    [3.68e-05, 3.52e-08, 3.24e-05]    []  
84000     [3.73e-05, 3.51e-08, 3.24e-05]    [3.68e-05, 3.51e-08, 3.24e-05]    []  
85000     [3.73e-05, 3.51e-08, 3.24e-05]    [3.67e-05, 3.51e-08, 3.24e-05]    []  
86000     [3.73e-05, 3.51e-08, 3.24e-05]    [3.67e-05, 3.51e-08, 3.24e-05]    []  

Best model at step 86000:
  train loss: 6.97e-05
  test loss: 6.91e-05
  test metric: []

'train' took 66.311852 s

Saving loss history to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/loss.dat ...
Saving training data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/train.dat ...
Saving test data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/test.dat ...
L2 relative error: 0.052206484542862606
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Burgers_RAR.py': No such file or directory
Using backend: pytorch

Warning: 10000 points required, but 10082 points sampled.
Compiling model...
'compile' took 0.000158 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d_exactBC.py", line 79, in <module>
    losshistory, train_state = model.train(iterations=10000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 287, in outputs_losses
    outputs_ = self.net(inputs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/nn/pytorch/fnn.py", line 47, in forward
    x = self._output_transform(inputs, x)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d_exactBC.py", line 67, in <lambda>
    lambda x, y: x[:, 1:2] * (1 - x[:, 0:1] ** 2) * y + tf.sin(np.pi * x[:, 0:1])
AttributeError: 'function' object has no attribute 'sin'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d_exactBC.py': No such file or directory
Using backend: pytorch

Warning: 10000 points required, but 10082 points sampled.
Compiling model...
'compile' took 0.000160 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d.py", line 80, in <module>
    losshistory, train_state = model.train(iterations=10000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 291, in outputs_losses
    losses = losses_fn(targets, outputs_, loss_fn, inputs, self)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/data.py", line 13, in losses_train
    return self.losses(targets, outputs, loss_fn, inputs, model, aux=aux)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/pde.py", line 127, in losses
    f = self.pde(inputs, outputs_pde)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d.py", line 25, in pde
    + tf.exp(-x[:, 1:])
AttributeError: 'function' object has no attribute 'exp'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d.py': No such file or directory
Using backend: pytorch

Warning: 10000 points required, but 10082 points sampled.
Compiling model...
'compile' took 0.000158 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d_resample.py", line 82, in <module>
    losshistory, train_state = model.train(iterations=2000, callbacks=[resampler])
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 291, in outputs_losses
    losses = losses_fn(targets, outputs_, loss_fn, inputs, self)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/data.py", line 13, in losses_train
    return self.losses(targets, outputs, loss_fn, inputs, model, aux=aux)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/pde.py", line 127, in losses
    f = self.pde(inputs, outputs_pde)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d_resample.py", line 25, in pde
    + tf.exp(-x[:, 1:])
AttributeError: 'function' object has no attribute 'exp'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_1d_resample.py': No such file or directory
Using backend: pytorch

Warning: 80000 points required, but 80117 points sampled.
Compiling model...
'compile' took 0.000183 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_reaction.py", line 110, in <module>
    losshistory, train_state = model.train(iterations=20000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 287, in outputs_losses
    outputs_ = self.net(inputs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/nn/pytorch/fnn.py", line 47, in forward
    x = self._output_transform(inputs, x)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_reaction.py", line 83, in output_transform
    + tf.sin(8 * x[:, 0:1]) / 8
AttributeError: 'function' object has no attribute 'sin'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/diffusion_reaction.py': No such file or directory
Using backend: pytorch

Compiling model...
'compile' took 0.000286 s

Training model...

Step      Train loss                                            Test loss                                             Test metric   
0         [1.81e+03, 2.65e+02, 1.75e-02, 2.42e+01, 1.22e-01]    [1.75e+03, 2.57e+02, 1.54e-02, 3.56e+01, 1.02e-01]    [1.14e+00]    
1000      [1.30e+01, 1.63e+00, 1.09e+00, 7.79e+00, 2.62e+01]    [2.32e+01, 3.72e+00, 5.38e-01, 1.11e+01, 3.96e+01]    [1.06e+00]    
2000      [3.25e+00, 3.34e-01, 6.97e-01, 2.28e+00, 1.29e+01]    [6.43e+00, 7.79e-01, 5.48e-01, 4.41e+00, 2.23e+01]    [8.28e-01]    
3000      [1.22e+00, 1.57e-01, 6.12e-01, 9.04e-01, 5.39e+00]    [2.67e+00, 2.68e-01, 1.09e+00, 3.50e+00, 1.18e+01]    [6.18e-01]    
4000      [7.24e-01, 1.45e-01, 4.30e-01, 4.03e-01, 2.01e+00]    [1.57e+00, 1.42e-01, 3.75e+00, 1.17e+01, 8.23e+00]    [4.83e-01]    
5000      [5.95e-01, 6.17e-02, 2.90e-01, 2.55e-01, 9.32e-01]    [1.27e+00, 5.86e-02, 4.77e+00, 1.54e+01, 7.04e+00]    [4.11e-01]    

Best model at step 5000:
  train loss: 2.13e+00
  test loss: 2.86e+01
  test metric: [4.11e-01]

'train' took 203.678910 s

Saving loss history to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/loss.dat ...
Saving training data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/train.dat ...
Saving test data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/test.dat ...
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/elasticity_plate.py': No such file or directory
Using backend: pytorch

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Euler_beam.py", line 46, in <module>
    num_test=100,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/pde.py", line 114, in __init__
    self.train_next_batch()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 37, in wrapper
    return func(self, *args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/pde.py", line 163, in train_next_batch
    self.train_x = self.bc_points()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 37, in wrapper
    return func(self, *args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/pde.py", line 256, in bc_points
    x_bcs = [bc.collocation_points(self.train_x_all) for bc in self.bcs]
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/pde.py", line 256, in <listcomp>
    x_bcs = [bc.collocation_points(self.train_x_all) for bc in self.bcs]
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/icbc/boundary_conditions.py", line 52, in collocation_points
    return self.filter(X)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/icbc/boundary_conditions.py", line 49, in filter
    return X[self.on_boundary(X, self.geom.on_boundary(X))]
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/icbc/boundary_conditions.py", line 40, in <lambda>
    [on_boundary(x[i], on[i]) for i in range(len(x))]
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/icbc/boundary_conditions.py", line 40, in <listcomp>
    [on_boundary(x[i], on[i]) for i in range(len(x))]
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Euler_beam.py", line 21, in boundary_l
    return on_boundary and dde.utils.isclose(x[0], 0)
AttributeError: module 'deepxde.utils.pytorch' has no attribute 'isclose'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/Euler_beam.py': No such file or directory
Using backend: pytorch

Compiling model...
'compile' took 0.000158 s

Training model...

Warning: assume zero boundary condition.
Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_diffusion_1d.py", line 104, in <module>
    losshistory, train_state = model.train(iterations=10000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 291, in outputs_losses
    losses = losses_fn(targets, outputs_, loss_fn, inputs, self)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/fpde.py", line 102, in losses_train
    f = self.pde(inputs, outputs, int_mat)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_diffusion_1d.py", line 21, in fpde
    lhs = -tf.matmul(int_mat, y)
AttributeError: 'function' object has no attribute 'matmul'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_diffusion_1d.py': No such file or directory
Using backend: pytorch

Compiling model...
'compile' took 0.000167 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_1d.py", line 77, in <module>
    losshistory, train_state = model.train(iterations=10000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 291, in outputs_losses
    losses = losses_fn(targets, outputs_, loss_fn, inputs, self)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/data/fpde.py", line 102, in losses_train
    f = self.pde(inputs, outputs, int_mat)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_1d.py", line 20, in fpde
    lhs = tf.matmul(int_mat, y)
AttributeError: 'function' object has no attribute 'matmul'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_1d.py': No such file or directory
Using backend: pytorch

Warning: mesh step size 0.010000 is larger than the boundary distance 0.007843.
Compiling model...
'compile' took 0.000160 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_2d.py", line 84, in <module>
    losshistory, train_state = model.train(iterations=20000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 287, in outputs_losses
    outputs_ = self.net(inputs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/nn/pytorch/fnn.py", line 47, in forward
    x = self._output_transform(inputs, x)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_2d.py", line 75, in <lambda>
    lambda x, y: (1 - tf.reduce_sum(x ** 2, axis=1, keepdims=True)) * y
AttributeError: 'function' object has no attribute 'reduce_sum'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_2d.py': No such file or directory
Using backend: pytorch

Warning: mesh step size 0.010000 is larger than the boundary distance 0.001304.
Compiling model...
'compile' took 0.000268 s

Training model...

Traceback (most recent call last):
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_3d.py", line 93, in <module>
    losshistory, train_state = model.train(iterations=10000)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/utils/internal.py", line 22, in wrapper
    result = f(*args, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 605, in train
    self._test()
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 796, in _test
    self.train_state.train_aux_vars,
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 517, in _outputs_losses
    outs = outputs_losses(inputs, targets)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 303, in outputs_losses_train
    return outputs_losses(True, inputs, targets, self.data.losses_train)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/model.py", line 287, in outputs_losses
    outputs_ = self.net(inputs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hrishikeshnk/.conda/envs/deepxde/lib/python3.6/site-packages/deepxde/nn/pytorch/fnn.py", line 47, in forward
    x = self._output_transform(inputs, x)
  File "/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_3d.py", line 84, in <lambda>
    lambda x, y: (1 - tf.reduce_sum(x ** 2, axis=1, keepdims=True)) * y
AttributeError: 'function' object has no attribute 'reduce_sum'
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/fractional_Poisson_3d.py': No such file or directory
Using backend: pytorch

Warning: 2540 points required, but 2550 points sampled.
Compiling model...
'compile' took 0.000152 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [2.49e-01, 9.23e-02, 4.24e-01]    [2.46e-01, 9.23e-02, 4.24e-01]    []  
1000      [1.36e-03, 3.45e-04, 2.92e-04]    [8.11e-04, 3.45e-04, 2.92e-04]    []  
2000      [2.20e-04, 2.82e-05, 2.40e-05]    [1.38e-04, 2.82e-05, 2.40e-05]    []  
3000      [1.00e-04, 1.21e-05, 8.35e-06]    [5.82e-05, 1.21e-05, 8.35e-06]    []  
4000      [5.95e-05, 7.96e-06, 4.48e-06]    [3.33e-05, 7.96e-06, 4.48e-06]    []  
5000      [4.37e-05, 6.45e-06, 3.62e-06]    [2.61e-05, 6.45e-06, 3.62e-06]    []  
6000      [3.37e-05, 4.31e-06, 2.11e-06]    [1.97e-05, 4.31e-06, 2.11e-06]    []  
7000      [2.74e-05, 3.20e-06, 1.58e-06]    [1.65e-05, 3.20e-06, 1.58e-06]    []  
8000      [2.83e-05, 2.74e-06, 4.88e-06]    [1.79e-05, 2.74e-06, 4.88e-06]    []  
9000      [2.02e-05, 1.72e-06, 1.04e-06]    [1.25e-05, 1.72e-06, 1.04e-06]    []  
10000     [4.17e-05, 2.33e-05, 5.81e-05]    [3.69e-05, 2.33e-05, 5.81e-05]    []  
11000     [1.49e-05, 1.58e-06, 8.20e-07]    [9.87e-06, 1.58e-06, 8.20e-07]    []  
12000     [1.30e-05, 1.06e-06, 8.04e-07]    [8.49e-06, 1.06e-06, 8.04e-07]    []  
13000     [1.16e-05, 9.02e-07, 4.71e-07]    [7.75e-06, 9.02e-07, 4.71e-07]    []  
14000     [1.05e-05, 8.90e-07, 5.52e-07]    [7.15e-06, 8.90e-07, 5.52e-07]    []  
15000     [9.75e-06, 7.52e-07, 3.57e-07]    [6.71e-06, 7.52e-07, 3.57e-07]    []  
16000     [9.49e-06, 1.08e-06, 1.58e-06]    [6.86e-06, 1.08e-06, 1.58e-06]    []  
17000     [1.20e-05, 2.65e-06, 5.72e-06]    [8.47e-06, 2.65e-06, 5.72e-06]    []  
18000     [8.21e-06, 6.38e-07, 3.15e-07]    [5.76e-06, 6.38e-07, 3.15e-07]    []  
19000     [1.30e-05, 8.72e-06, 1.86e-05]    [9.67e-06, 8.72e-06, 1.86e-05]    []  
20000     [7.52e-06, 6.43e-07, 3.27e-07]    [5.17e-06, 6.43e-07, 3.27e-07]    []  

Best model at step 20000:
  train loss: 8.49e-06
  test loss: 6.14e-06
  test metric: []

'train' took 84.917700 s

Compiling model...
'compile' took 0.000170 s

Training model...

Step      Train loss                        Test loss                         Test metric
20000     [7.52e-06, 6.43e-07, 3.27e-07]    [5.17e-06, 6.43e-07, 3.27e-07]    []  
21000     [7.44e-06, 5.88e-07, 2.35e-07]    [5.17e-06, 5.88e-07, 2.35e-07]    []  
22000     [7.44e-06, 5.87e-07, 2.35e-07]    [5.17e-06, 5.87e-07, 2.35e-07]    []  
23000     [7.43e-06, 5.87e-07, 2.36e-07]    [5.17e-06, 5.87e-07, 2.36e-07]    []  
24000     [7.43e-06, 5.87e-07, 2.36e-07]    [5.17e-06, 5.87e-07, 2.36e-07]    []  
25000     [7.43e-06, 5.86e-07, 2.37e-07]    [5.17e-06, 5.86e-07, 2.37e-07]    []  
26000     [7.43e-06, 5.86e-07, 2.37e-07]    [5.17e-06, 5.86e-07, 2.37e-07]    []  
27000     [7.43e-06, 5.86e-07, 2.38e-07]    [5.17e-06, 5.86e-07, 2.38e-07]    []  
28000     [7.42e-06, 5.86e-07, 2.38e-07]    [5.17e-06, 5.86e-07, 2.38e-07]    []  
29000     [7.42e-06, 5.85e-07, 2.38e-07]    [5.17e-06, 5.85e-07, 2.38e-07]    []  
30000     [7.42e-06, 5.85e-07, 2.39e-07]    [5.17e-06, 5.85e-07, 2.39e-07]    []  
31000     [7.42e-06, 5.85e-07, 2.39e-07]    [5.17e-06, 5.85e-07, 2.39e-07]    []  
32000     [7.42e-06, 5.85e-07, 2.40e-07]    [5.17e-06, 5.85e-07, 2.40e-07]    []  
33000     [7.41e-06, 5.85e-07, 2.40e-07]    [5.17e-06, 5.85e-07, 2.40e-07]    []  
34000     [7.41e-06, 5.84e-07, 2.40e-07]    [5.17e-06, 5.84e-07, 2.40e-07]    []  
35000     [7.41e-06, 5.84e-07, 2.40e-07]    [5.17e-06, 5.84e-07, 2.40e-07]    []  

Best model at step 35000:
  train loss: 8.23e-06
  test loss: 5.99e-06
  test metric: []

'train' took 64.739794 s

Saving loss history to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/loss.dat ...
Saving training data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/train.dat ...
Saving test data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/test.dat ...
Mean residual: 0.0018430431
L2 relative error: 0.0016789817917411674
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/heat.py': No such file or directory
Using backend: pytorch

Warning: 2540 points required, but 2550 points sampled.
Compiling model...
'compile' took 0.000152 s

Training model...

Step      Train loss                        Test loss                         Test metric
0         [6.12e-02, 1.35e-01, 2.94e-01]    [6.06e-02, 1.35e-01, 2.94e-01]    []  
1000      [8.32e-04, 1.52e-04, 2.51e-04]    [5.28e-04, 1.52e-04, 2.51e-04]    []  
2000      [1.94e-04, 2.38e-05, 1.27e-05]    [1.08e-04, 2.38e-05, 1.27e-05]    []  
3000      [1.06e-04, 1.03e-05, 4.07e-06]    [7.64e-05, 1.03e-05, 4.07e-06]    []  
4000      [5.78e-05, 3.70e-06, 1.00e-06]    [3.64e-05, 3.70e-06, 1.00e-06]    []  
5000      [1.70e-04, 1.55e-05, 7.86e-05]    [1.32e-04, 1.55e-05, 7.86e-05]    []  
6000      [4.86e-05, 2.28e-05, 1.26e-05]    [3.08e-05, 2.28e-05, 1.26e-05]    []  
7000      [2.72e-05, 1.06e-06, 1.64e-07]    [1.80e-05, 1.06e-06, 1.64e-07]    []  
8000      [2.88e-05, 6.31e-06, 2.61e-06]    [1.97e-05, 6.31e-06, 2.61e-06]    []  
9000      [1.99e-05, 7.62e-07, 1.22e-07]    [1.31e-05, 7.62e-07, 1.22e-07]    []  
10000     [2.86e-05, 1.37e-06, 4.33e-06]    [2.26e-05, 1.37e-06, 4.33e-06]    []  
11000     [3.45e-05, 3.63e-06, 1.42e-05]    [2.87e-05, 3.63e-06, 1.42e-05]    []  
12000     [2.30e-05, 1.78e-06, 4.65e-06]    [1.62e-05, 1.78e-06, 4.65e-06]    []  
13000     [1.27e-05, 6.40e-07, 3.90e-07]    [8.67e-06, 6.40e-07, 3.90e-07]    []  
14000     [1.25e-05, 6.40e-07, 2.22e-07]    [8.14e-06, 6.40e-07, 2.22e-07]    []  
15000     [7.42e-05, 8.10e-06, 3.63e-05]    [6.01e-05, 8.10e-06, 3.63e-05]    []  
16000     [1.15e-05, 3.35e-06, 3.24e-06]    [7.76e-06, 3.35e-06, 3.24e-06]    []  
17000     [1.58e-05, 1.02e-06, 1.87e-06]    [1.12e-05, 1.02e-06, 1.87e-06]    []  
18000     [9.57e-06, 5.70e-07, 2.40e-07]    [6.48e-06, 5.70e-07, 2.40e-07]    []  
19000     [9.19e-05, 1.19e-04, 2.43e-04]    [8.84e-05, 1.19e-04, 2.43e-04]    []  
20000     [8.07e-06, 1.07e-06, 7.95e-07]    [5.74e-06, 1.07e-06, 7.95e-07]    []  
21000     [8.09e-06, 5.91e-07, 1.93e-07]    [5.58e-06, 5.91e-07, 1.93e-07]    []  
22000     [7.74e-06, 6.07e-07, 2.22e-07]    [5.67e-06, 6.07e-07, 2.22e-07]    []  
23000     [7.93e-06, 5.99e-06, 6.89e-06]    [5.63e-06, 5.99e-06, 6.89e-06]    []  
24000     [6.76e-06, 6.01e-07, 2.04e-07]    [4.75e-06, 6.01e-07, 2.04e-07]    []  
25000     [6.75e-06, 8.05e-07, 1.79e-07]    [4.88e-06, 8.05e-07, 1.79e-07]    []  
26000     [4.18e-05, 2.06e-05, 9.29e-06]    [2.85e-05, 2.06e-05, 9.29e-06]    []  
27000     [6.14e-06, 6.86e-07, 4.84e-07]    [4.42e-06, 6.86e-07, 4.84e-07]    []  
28000     [5.20e-06, 5.66e-07, 1.84e-07]    [3.93e-06, 5.66e-07, 1.84e-07]    []  
29000     [5.13e-06, 5.35e-07, 1.53e-07]    [3.78e-06, 5.35e-07, 1.53e-07]    []  
30000     [9.12e-06, 4.96e-06, 3.46e-06]    [6.23e-06, 4.96e-06, 3.46e-06]    []  
31000     [5.07e-06, 5.20e-07, 1.68e-07]    [3.69e-06, 5.20e-07, 1.68e-07]    []  
32000     [5.00e-06, 5.24e-07, 1.49e-07]    [3.63e-06, 5.24e-07, 1.49e-07]    []  
33000     [3.16e-05, 4.35e-06, 1.58e-05]    [2.63e-05, 4.35e-06, 1.58e-05]    []  
34000     [3.89e-06, 4.71e-07, 1.30e-07]    [3.02e-06, 4.71e-07, 1.30e-07]    []  
35000     [6.33e-06, 8.23e-07, 1.50e-06]    [4.88e-06, 8.23e-07, 1.50e-06]    []  
36000     [4.24e-06, 4.46e-07, 2.36e-07]    [3.18e-06, 4.46e-07, 2.36e-07]    []  
37000     [3.74e-06, 4.18e-07, 1.21e-07]    [2.75e-06, 4.18e-07, 1.21e-07]    []  
38000     [1.38e-05, 2.57e-05, 2.20e-05]    [9.02e-06, 2.57e-05, 2.20e-05]    []  
39000     [7.27e-06, 8.31e-07, 2.03e-06]    [5.71e-06, 8.31e-07, 2.03e-06]    []  
40000     [3.74e-06, 4.39e-07, 3.87e-07]    [2.91e-06, 4.39e-07, 3.87e-07]    []  
41000     [9.39e-05, 1.76e-05, 6.19e-05]    [8.01e-05, 1.76e-05, 6.19e-05]    []  
42000     [3.02e-06, 3.36e-07, 1.02e-07]    [2.28e-06, 3.36e-07, 1.02e-07]    []  
43000     [1.31e-05, 9.39e-07, 3.68e-06]    [1.10e-05, 9.39e-07, 3.68e-06]    []  
44000     [2.79e-06, 3.05e-07, 9.60e-08]    [2.08e-06, 3.05e-07, 9.60e-08]    []  
45000     [2.78e-06, 2.96e-07, 1.14e-07]    [2.07e-06, 2.96e-07, 1.14e-07]    []  
46000     [1.53e-05, 1.81e-06, 6.38e-06]    [1.29e-05, 1.81e-06, 6.38e-06]    []  
47000     [2.46e-06, 2.58e-07, 8.61e-08]    [1.82e-06, 2.58e-07, 8.61e-08]    []  
48000     [1.26e-04, 2.58e-05, 8.49e-05]    [1.08e-04, 2.58e-05, 8.49e-05]    []  
49000     [1.01e-05, 8.84e-06, 5.75e-06]    [7.01e-06, 8.84e-06, 5.75e-06]    []  
50000     [1.90e-05, 7.78e-07, 1.39e-06]    [1.51e-05, 7.78e-07, 1.39e-06]    []  
51000     [2.42e-06, 2.14e-07, 1.82e-07]    [1.85e-06, 2.14e-07, 1.82e-07]    []  
52000     [1.08e-05, 1.00e-06, 3.71e-06]    [8.77e-06, 1.00e-06, 3.71e-06]    []  
53000     [1.94e-06, 1.80e-07, 9.20e-08]    [1.46e-06, 1.80e-07, 9.20e-08]    []  
54000     [1.81e-06, 2.07e-07, 8.22e-08]    [1.39e-06, 2.07e-07, 8.22e-08]    []  
55000     [1.82e-06, 1.61e-07, 6.73e-08]    [1.34e-06, 1.61e-07, 6.73e-08]    []  
56000     [1.72e-06, 1.49e-07, 6.09e-08]    [1.30e-06, 1.49e-07, 6.09e-08]    []  
57000     [6.83e-05, 5.48e-06, 2.85e-05]    [5.73e-05, 5.48e-06, 2.85e-05]    []  
58000     [1.65e-06, 1.63e-07, 1.18e-07]    [1.22e-06, 1.63e-07, 1.18e-07]    []  
59000     [1.60e-06, 1.26e-07, 7.01e-08]    [1.20e-06, 1.26e-07, 7.01e-08]    []  
60000     [1.85e-06, 3.91e-07, 1.89e-07]    [1.33e-06, 3.91e-07, 1.89e-07]    []  
61000     [1.54e-06, 1.14e-07, 5.20e-08]    [1.12e-06, 1.14e-07, 5.20e-08]    []  
62000     [8.00e-06, 1.07e-06, 3.42e-06]    [6.56e-06, 1.07e-06, 3.42e-06]    []  
63000     [1.47e-06, 1.38e-07, 1.04e-07]    [1.12e-06, 1.38e-07, 1.04e-07]    []  
64000     [1.60e-06, 5.32e-07, 6.32e-07]    [1.16e-06, 5.32e-07, 6.32e-07]    []  
65000     [1.35e-06, 1.00e-07, 4.16e-08]    [1.05e-06, 1.00e-07, 4.16e-08]    []  
66000     [1.49e-06, 9.32e-08, 8.28e-08]    [1.10e-06, 9.32e-08, 8.28e-08]    []  
67000     [1.45e-06, 8.48e-08, 4.33e-08]    [1.04e-06, 8.48e-08, 4.33e-08]    []  
68000     [1.38e-06, 8.39e-08, 4.06e-08]    [1.02e-06, 8.39e-08, 4.06e-08]    []  
69000     [1.32e-05, 2.17e-06, 6.79e-06]    [1.11e-05, 2.17e-06, 6.79e-06]    []  
70000     [1.66e-06, 1.17e-07, 2.13e-07]    [1.21e-06, 1.17e-07, 2.13e-07]    []  
71000     [3.69e-06, 3.70e-07, 1.07e-06]    [2.89e-06, 3.70e-07, 1.07e-06]    []  
72000     [1.40e-06, 7.75e-08, 3.91e-08]    [9.89e-07, 7.75e-08, 3.91e-08]    []  
73000     [1.55e-06, 1.26e-07, 3.08e-08]    [1.11e-06, 1.26e-07, 3.08e-08]    []  
74000     [1.36e-06, 1.63e-07, 1.18e-07]    [9.62e-07, 1.63e-07, 1.18e-07]    []  
75000     [1.65e-06, 2.65e-07, 1.41e-07]    [1.17e-06, 2.65e-07, 1.41e-07]    []  
76000     [1.37e-06, 6.71e-08, 3.46e-08]    [9.49e-07, 6.71e-08, 3.46e-08]    []  
77000     [1.32e-06, 7.95e-08, 5.29e-08]    [9.34e-07, 7.95e-08, 5.29e-08]    []  
78000     [1.31e-06, 6.60e-08, 3.49e-08]    [9.36e-07, 6.60e-08, 3.49e-08]    []  
79000     [1.27e-06, 6.60e-08, 2.93e-08]    [9.18e-07, 6.60e-08, 2.93e-08]    []  
80000     [4.08e-05, 2.45e-06, 1.08e-05]    [3.37e-05, 2.45e-06, 1.08e-05]    []  
81000     [1.02e-05, 2.50e-06, 6.39e-06]    [8.64e-06, 2.50e-06, 6.39e-06]    []  
82000     [1.25e-06, 6.72e-08, 5.73e-08]    [9.17e-07, 6.72e-08, 5.73e-08]    []  
83000     [4.17e-05, 7.33e-06, 2.23e-05]    [3.53e-05, 7.33e-06, 2.23e-05]    []  
84000     [1.28e-06, 5.68e-08, 3.58e-08]    [8.99e-07, 5.68e-08, 3.58e-08]    []  
85000     [4.44e-06, 4.47e-07, 1.36e-06]    [3.55e-06, 4.47e-07, 1.36e-06]    []  
86000     [1.27e-06, 6.91e-08, 3.92e-08]    [9.26e-07, 6.91e-08, 3.92e-08]    []  
87000     [1.41e-05, 1.05e-05, 6.43e-06]    [1.02e-05, 1.05e-05, 6.43e-06]    []  
88000     [1.35e-06, 9.48e-08, 1.09e-07]    [9.66e-07, 9.48e-08, 1.09e-07]    []  
89000     [3.12e-06, 2.37e-07, 7.04e-07]    [2.45e-06, 2.37e-07, 7.04e-07]    []  
90000     [1.24e-06, 5.81e-08, 2.86e-08]    [8.69e-07, 5.81e-08, 2.86e-08]    []  
91000     [1.24e-06, 6.05e-08, 4.84e-08]    [8.83e-07, 6.05e-08, 4.84e-08]    []  
92000     [1.55e-06, 1.17e-07, 1.90e-07]    [1.14e-06, 1.17e-07, 1.90e-07]    []  
93000     [1.72e-06, 1.90e-06, 1.87e-06]    [1.21e-06, 1.90e-06, 1.87e-06]    []  
94000     [1.31e-06, 7.26e-08, 6.62e-08]    [9.21e-07, 7.26e-08, 6.62e-08]    []  
95000     [1.17e-06, 5.66e-08, 3.57e-08]    [8.39e-07, 5.66e-08, 3.57e-08]    []  
96000     [1.68e-06, 2.45e-07, 1.05e-07]    [1.27e-06, 2.45e-07, 1.05e-07]    []  
97000     [1.87e-06, 9.50e-07, 6.45e-07]    [1.28e-06, 9.50e-07, 6.45e-07]    []  
98000     [1.29e-06, 8.63e-08, 4.52e-08]    [9.37e-07, 8.63e-08, 4.52e-08]    []  
99000     [5.98e-06, 1.62e-06, 5.29e-07]    [4.42e-06, 1.62e-06, 5.29e-07]    []  
100000    [1.17e-06, 9.71e-08, 5.75e-08]    [8.43e-07, 9.71e-08, 5.75e-08]    []  
101000    [3.86e-05, 1.30e-06, 5.96e-06]    [3.14e-05, 1.30e-06, 5.96e-06]    []  
102000    [1.32e-06, 1.10e-07, 2.11e-07]    [9.80e-07, 1.10e-07, 2.11e-07]    []  
103000    [1.10e-06, 5.17e-08, 3.24e-08]    [7.97e-07, 5.17e-08, 3.24e-08]    []  
104000    [1.62e-05, 1.17e-05, 6.79e-06]    [1.16e-05, 1.17e-05, 6.79e-06]    []  
105000    [1.94e-06, 3.28e-07, 6.69e-07]    [1.54e-06, 3.28e-07, 6.69e-07]    []  
106000    [1.29e-06, 2.44e-07, 1.64e-07]    [9.25e-07, 2.44e-07, 1.64e-07]    []  
107000    [1.31e-06, 7.12e-08, 1.14e-07]    [9.65e-07, 7.12e-08, 1.14e-07]    []  
108000    [1.08e-06, 5.42e-08, 2.81e-08]    [7.75e-07, 5.42e-08, 2.81e-08]    []  
109000    [1.08e-06, 1.00e-07, 8.10e-08]    [7.74e-07, 1.00e-07, 8.10e-08]    []  
110000    [4.46e-06, 3.71e-07, 1.37e-06]    [3.59e-06, 3.71e-07, 1.37e-06]    []  
111000    [2.24e-06, 1.57e-07, 4.14e-07]    [1.76e-06, 1.57e-07, 4.14e-07]    []  
112000    [1.16e-06, 1.14e-07, 4.58e-08]    [8.41e-07, 1.14e-07, 4.58e-08]    []  
113000    [1.21e-06, 4.89e-08, 4.86e-08]    [8.88e-07, 4.89e-08, 4.86e-08]    []  
114000    [1.04e-06, 5.01e-08, 2.70e-08]    [7.54e-07, 5.01e-08, 2.70e-08]    []  
115000    [1.17e-06, 5.29e-07, 4.92e-07]    [8.36e-07, 5.29e-07, 4.92e-07]    []  
116000    [1.11e-06, 1.61e-07, 2.26e-07]    [8.15e-07, 1.61e-07, 2.26e-07]    []  
117000    [1.05e-06, 5.05e-08, 2.72e-08]    [7.46e-07, 5.05e-08, 2.72e-08]    []  
118000    [1.04e-06, 5.43e-08, 2.80e-08]    [7.49e-07, 5.43e-08, 2.80e-08]    []  
119000    [9.37e-06, 1.42e-06, 4.12e-06]    [7.72e-06, 1.42e-06, 4.12e-06]    []  
120000    [1.23e-06, 2.22e-07, 2.26e-07]    [8.43e-07, 2.22e-07, 2.26e-07]    []  
121000    [1.27e-05, 1.71e-06, 5.33e-06]    [1.06e-05, 1.71e-06, 5.33e-06]    []  
122000    [1.00e-06, 4.76e-08, 2.75e-08]    [7.18e-07, 4.76e-08, 2.75e-08]    []  
123000    [8.44e-06, 2.12e-06, 5.79e-07]    [6.26e-06, 2.12e-06, 5.79e-07]    []  
124000    [9.78e-07, 5.01e-08, 2.98e-08]    [7.11e-07, 5.01e-08, 2.98e-08]    []  
125000    [1.40e-05, 6.00e-06, 2.77e-06]    [1.02e-05, 6.00e-06, 2.77e-06]    []  
126000    [1.65e-05, 1.20e-05, 7.33e-06]    [1.17e-05, 1.20e-05, 7.33e-06]    []  
127000    [1.22e-06, 7.31e-08, 1.10e-07]    [8.93e-07, 7.31e-08, 1.10e-07]    []  
128000    [1.08e-06, 1.97e-07, 3.25e-07]    [7.97e-07, 1.97e-07, 3.25e-07]    []  
129000    [9.76e-07, 4.22e-08, 2.97e-08]    [7.11e-07, 4.22e-08, 2.97e-08]    []  
130000    [1.20e-06, 6.04e-08, 1.21e-07]    [8.99e-07, 6.04e-08, 1.21e-07]    []  
131000    [7.58e-06, 2.44e-06, 5.75e-06]    [6.45e-06, 2.44e-06, 5.75e-06]    []  
132000    [4.10e-06, 1.63e-05, 1.96e-05]    [3.35e-06, 1.63e-05, 1.96e-05]    []  
133000    [9.69e-07, 6.39e-08, 5.19e-08]    [7.01e-07, 6.39e-08, 5.19e-08]    []  
134000    [1.11e-06, 9.34e-08, 1.33e-07]    [8.13e-07, 9.34e-08, 1.33e-07]    []  
135000    [1.10e-06, 4.14e-08, 4.04e-08]    [8.14e-07, 4.14e-08, 4.04e-08]    []  
136000    [5.18e-06, 6.89e-07, 2.04e-06]    [4.25e-06, 6.89e-07, 2.04e-06]    []  
137000    [1.13e-06, 1.03e-07, 1.48e-07]    [8.15e-07, 1.03e-07, 1.48e-07]    []  
138000    [2.61e-06, 4.33e-07, 1.15e-06]    [2.13e-06, 4.33e-07, 1.15e-06]    []  
139000    [1.35e-06, 1.01e-07, 2.40e-07]    [1.05e-06, 1.01e-07, 2.40e-07]    []  
140000    [1.17e-06, 8.06e-08, 1.74e-07]    [8.86e-07, 8.06e-08, 1.74e-07]    []  
141000    [1.30e-06, 7.44e-08, 1.25e-07]    [9.52e-07, 7.44e-08, 1.25e-07]    []  
142000    [8.25e-06, 4.25e-07, 1.71e-06]    [6.66e-06, 4.25e-07, 1.71e-06]    []  
143000    [9.29e-07, 3.94e-08, 3.26e-08]    [6.84e-07, 3.94e-08, 3.26e-08]    []  
144000    [1.08e-06, 1.52e-07, 1.46e-07]    [8.30e-07, 1.52e-07, 1.46e-07]    []  
145000    [9.12e-07, 3.68e-08, 3.19e-08]    [6.71e-07, 3.68e-08, 3.19e-08]    []  
146000    [9.50e-07, 5.50e-08, 5.23e-08]    [6.95e-07, 5.50e-08, 5.23e-08]    []  
147000    [9.10e-07, 3.88e-08, 2.84e-08]    [6.65e-07, 3.88e-08, 2.84e-08]    []  
148000    [1.02e-06, 6.87e-08, 9.43e-08]    [7.36e-07, 6.87e-08, 9.43e-08]    []  
149000    [9.25e-07, 4.02e-08, 2.81e-08]    [6.89e-07, 4.02e-08, 2.81e-08]    []  
150000    [1.04e-06, 7.49e-07, 9.11e-07]    [7.81e-07, 7.49e-07, 9.11e-07]    []  
151000    [9.55e-07, 3.68e-08, 3.26e-08]    [7.05e-07, 3.68e-08, 3.26e-08]    []  
152000    [2.65e-06, 3.55e-07, 1.04e-06]    [2.16e-06, 3.55e-07, 1.04e-06]    []  
153000    [3.81e-05, 8.37e-06, 2.35e-05]    [3.19e-05, 8.37e-06, 2.35e-05]    []  
154000    [2.96e-05, 5.61e-06, 1.45e-05]    [2.42e-05, 5.61e-06, 1.45e-05]    []  
155000    [9.97e-07, 6.15e-08, 1.11e-07]    [7.46e-07, 6.15e-08, 1.11e-07]    []  
156000    [9.54e-07, 1.40e-07, 1.00e-07]    [6.83e-07, 1.40e-07, 1.00e-07]    []  
157000    [1.41e-06, 2.50e-07, 4.26e-07]    [1.03e-06, 2.50e-07, 4.26e-07]    []  
158000    [9.57e-07, 5.73e-08, 8.15e-08]    [7.31e-07, 5.73e-08, 8.15e-08]    []  
159000    [3.99e-06, 1.13e-06, 4.23e-07]    [2.91e-06, 1.13e-06, 4.23e-07]    []  
160000    [8.75e-07, 3.50e-08, 2.90e-08]    [6.44e-07, 3.50e-08, 2.90e-08]    []  
161000    [9.36e-07, 4.64e-08, 6.33e-08]    [7.07e-07, 4.64e-08, 6.33e-08]    []  
162000    [1.09e-06, 1.07e-07, 2.34e-07]    [8.42e-07, 1.07e-07, 2.34e-07]    []  
163000    [8.73e-07, 3.52e-08, 2.74e-08]    [6.35e-07, 3.52e-08, 2.74e-08]    []  
164000    [8.65e-07, 3.59e-08, 2.52e-08]    [6.31e-07, 3.59e-08, 2.52e-08]    []  
165000    [9.62e-06, 4.00e-06, 8.58e-06]    [8.22e-06, 4.00e-06, 8.58e-06]    []  
166000    [9.38e-07, 6.50e-08, 7.99e-08]    [6.83e-07, 6.50e-08, 7.99e-08]    []  
167000    [4.67e-06, 1.21e-06, 2.75e-06]    [3.72e-06, 1.21e-06, 2.75e-06]    []  
168000    [8.68e-07, 3.40e-08, 2.81e-08]    [6.34e-07, 3.40e-08, 2.81e-08]    []  
169000    [6.46e-05, 1.49e-05, 3.78e-05]    [5.38e-05, 1.49e-05, 3.78e-05]    []  
170000    [1.36e-05, 1.77e-06, 5.00e-06]    [1.09e-05, 1.77e-06, 5.00e-06]    []  
171000    [2.04e-06, 9.29e-07, 5.40e-07]    [1.46e-06, 9.29e-07, 5.40e-07]    []  
172000    [3.57e-06, 2.59e-07, 7.44e-07]    [2.70e-06, 2.59e-07, 7.44e-07]    []  
173000    [9.34e-07, 4.66e-08, 3.69e-08]    [6.65e-07, 4.66e-08, 3.69e-08]    []  
174000    [3.47e-06, 1.55e-06, 8.70e-07]    [2.48e-06, 1.55e-06, 8.70e-07]    []  
175000    [3.89e-05, 7.53e-06, 2.07e-05]    [3.16e-05, 7.53e-06, 2.07e-05]    []  
176000    [1.43e-06, 1.56e-07, 4.21e-07]    [1.14e-06, 1.56e-07, 4.21e-07]    []  
177000    [1.70e-06, 3.04e-07, 7.03e-07]    [1.39e-06, 3.04e-07, 7.03e-07]    []  
178000    [1.65e-05, 1.05e-05, 6.19e-06]    [1.18e-05, 1.05e-05, 6.19e-06]    []  
179000    [2.79e-05, 7.93e-06, 1.89e-05]    [2.32e-05, 7.93e-06, 1.89e-05]    []  
180000    [1.07e-05, 1.80e-06, 5.38e-06]    [8.90e-06, 1.80e-06, 5.38e-06]    []  
181000    [8.23e-07, 3.44e-08, 2.69e-08]    [6.09e-07, 3.44e-08, 2.69e-08]    []  
182000    [6.73e-06, 1.01e-05, 1.03e-05]    [5.06e-06, 1.01e-05, 1.03e-05]    []  
183000    [8.62e-07, 3.31e-08, 3.28e-08]    [6.43e-07, 3.31e-08, 3.28e-08]    []  
184000    [1.57e-06, 8.28e-08, 2.51e-07]    [1.23e-06, 8.28e-08, 2.51e-07]    []  
185000    [8.81e-07, 4.47e-08, 7.11e-08]    [6.73e-07, 4.47e-08, 7.11e-08]    []  
186000    [8.01e-07, 3.70e-08, 2.93e-08]    [5.92e-07, 3.70e-08, 2.93e-08]    []  
187000    [1.04e-06, 9.79e-08, 1.52e-07]    [7.63e-07, 9.79e-08, 1.52e-07]    []  
188000    [5.57e-06, 1.19e-06, 2.84e-06]    [4.45e-06, 1.19e-06, 2.84e-06]    []  
189000    [1.95e-06, 2.34e-07, 6.40e-07]    [1.57e-06, 2.34e-07, 6.40e-07]    []  
190000    [1.31e-06, 2.38e-07, 1.06e-07]    [9.32e-07, 2.38e-07, 1.06e-07]    []  
191000    [6.40e-05, 1.39e-05, 3.85e-05]    [5.23e-05, 1.39e-05, 3.85e-05]    []  
192000    [6.80e-06, 4.33e-06, 2.64e-06]    [4.83e-06, 4.33e-06, 2.64e-06]    []  
193000    [2.30e-06, 1.28e-07, 3.32e-08]    [1.70e-06, 1.28e-07, 3.32e-08]    []  
194000    [1.95e-06, 2.42e-07, 6.52e-07]    [1.57e-06, 2.42e-07, 6.52e-07]    []  
195000    [1.43e-04, 3.59e-05, 8.63e-05]    [1.18e-04, 3.59e-05, 8.63e-05]    []  
196000    [1.52e-05, 3.27e-06, 8.49e-06]    [1.26e-05, 3.27e-06, 8.49e-06]    []  
197000    [1.27e-05, 1.19e-05, 8.60e-06]    [8.92e-06, 1.19e-05, 8.60e-06]    []  
198000    [7.67e-07, 3.27e-08, 2.52e-08]    [5.74e-07, 3.27e-08, 2.52e-08]    []  
199000    [4.29e-06, 7.40e-07, 1.42e-07]    [3.20e-06, 7.40e-07, 1.42e-07]    []  
200000    [7.75e-07, 3.18e-08, 2.48e-08]    [5.81e-07, 3.18e-08, 2.48e-08]    []  

Best model at step 198000:
  train loss: 8.25e-07
  test loss: 6.32e-07
  test metric: []

'train' took 1359.403238 s

Compiling model...
'compile' took 0.000182 s

Training model...

Step      Train loss                        Test loss                         Test metric
200000    [7.70e-07, 3.18e-08, 2.48e-08]    [5.81e-07, 3.18e-08, 2.48e-08]    []  
201000    [7.64e-07, 3.24e-08, 2.38e-08]    [5.72e-07, 3.24e-08, 2.38e-08]    []  
202000    [7.64e-07, 3.24e-08, 2.38e-08]    [5.72e-07, 3.24e-08, 2.38e-08]    []  
203000    [7.64e-07, 3.24e-08, 2.38e-08]    [5.72e-07, 3.24e-08, 2.38e-08]    []  
204000    [7.64e-07, 3.24e-08, 2.38e-08]    [5.72e-07, 3.24e-08, 2.38e-08]    []  
205000    [7.63e-07, 3.24e-08, 2.38e-08]    [5.71e-07, 3.24e-08, 2.38e-08]    []  
206000    [7.63e-07, 3.24e-08, 2.38e-08]    [5.71e-07, 3.24e-08, 2.38e-08]    []  
207000    [7.63e-07, 3.24e-08, 2.38e-08]    [5.71e-07, 3.24e-08, 2.38e-08]    []  
208000    [7.63e-07, 3.24e-08, 2.37e-08]    [5.71e-07, 3.24e-08, 2.37e-08]    []  
209000    [7.63e-07, 3.24e-08, 2.37e-08]    [5.71e-07, 3.24e-08, 2.37e-08]    []  
210000    [7.63e-07, 3.24e-08, 2.37e-08]    [5.71e-07, 3.24e-08, 2.37e-08]    []  
211000    [7.55e-07, 3.23e-08, 2.38e-08]    [5.70e-07, 3.23e-08, 2.38e-08]    []  
212000    [7.54e-07, 3.22e-08, 2.39e-08]    [5.70e-07, 3.22e-08, 2.39e-08]    []  
213000    [7.54e-07, 3.22e-08, 2.38e-08]    [5.69e-07, 3.22e-08, 2.38e-08]    []  
214000    [7.54e-07, 3.22e-08, 2.38e-08]    [5.69e-07, 3.22e-08, 2.38e-08]    []  
215000    [7.54e-07, 3.22e-08, 2.38e-08]    [5.69e-07, 3.22e-08, 2.38e-08]    []  

Best model at step 215000:
  train loss: 8.10e-07
  test loss: 6.25e-07
  test metric: []

'train' took 65.545731 s

Saving loss history to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/loss.dat ...
Saving training data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/train.dat ...
Saving test data to /home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/test.dat ...
Mean residual: 0.00058255787
L2 relative error: 0.0005015997470639228
mv: cannot stat '/home/hrishikeshnk/github.copy/deepxde/examples/pinn_forward/heat_resample.py': No such file or directory
Using backend: pytorch

0 it number
learning rate: 1.0e-03
num_dense_layers: 4
num_dense_nodes: 50
activation: sin

Compiling model...
'compile' took 0.000167 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [2.10e+02]    [2.71e+02]    [5.60e-01]    
2000      [8.46e+01]    [9.93e+02]    [5.87e-01]    
3000      [1.24e+01]    [4.00e+03]    [7.73e-01]    
4000      [3.24e+00]    [4.70e+03]    [8.41e-01]    
5000      [6.12e+00]    [4.85e+03]    [8.66e-01]    
6000      [3.40e+00]    [4.71e+03]    [8.73e-01]    
7000      [1.20e+00]    [4.51e+03]    [8.72e-01]    
8000      [8.12e-01]    [4.44e+03]    [8.73e-01]    
9000      [1.19e+00]    [4.25e+03]    [8.72e-01]    
10000     [2.85e+00]    [4.15e+03]    [8.69e-01]    

Best model at step 8000:
  train loss: 8.12e-01
  test loss: 4.44e+03
  test metric: [8.73e-01]

'train' took 105.367162 s

1 it number
learning rate: 2.2e-03
num_dense_layers: 8
num_dense_nodes: 308
activation: tanh

Compiling model...
'compile' took 0.000154 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
6000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
7000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
8000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
9000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
10000     [5.21e+03]    [6.44e+03]    [1.00e+00]    

Best model at step 6000:
  train loss: 5.21e+03
  test loss: 6.44e+03
  test metric: [1.00e+00]

'train' took 167.533474 s

2 it number
learning rate: 2.1e-02
num_dense_layers: 2
num_dense_nodes: 103
activation: tanh

Compiling model...
'compile' took 0.008828 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.05e+03]    [6.99e+03]    [1.00e+00]    
2000      [4.57e+02]    [9.05e+03]    [1.04e+00]    
3000      [5.48e+02]    [9.06e+03]    [1.04e+00]    
4000      [1.69e+03]    [1.04e+04]    [1.09e+00]    
5000      [3.44e+02]    [8.96e+03]    [1.14e+00]    
6000      [2.83e+02]    [9.01e+03]    [1.16e+00]    
7000      [2.11e+02]    [8.33e+03]    [1.19e+00]    
8000      [1.78e+02]    [7.72e+03]    [1.22e+00]    
9000      [1.46e+02]    [7.29e+03]    [1.21e+00]    
10000     [1.09e+02]    [7.25e+03]    [1.24e+00]    

Best model at step 10000:
  train loss: 1.09e+02
  test loss: 7.25e+03
  test metric: [1.24e+00]

'train' took 78.752633 s

3 it number
learning rate: 2.7e-04
num_dense_layers: 2
num_dense_nodes: 11
activation: sin

Compiling model...
'compile' took 0.000102 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.45e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [4.92e+03]    [6.08e+03]    [9.72e-01]    
6000      [4.55e+03]    [5.62e+03]    [9.32e-01]    
7000      [4.14e+03]    [5.09e+03]    [8.98e-01]    
8000      [3.43e+03]    [4.08e+03]    [9.03e-01]    
9000      [3.18e+03]    [3.73e+03]    [9.41e-01]    
10000     [2.35e+03]    [2.77e+03]    [8.38e-01]    

Best model at step 10000:
  train loss: 2.35e+03
  test loss: 2.77e+03
  test metric: [8.38e-01]

'train' took 79.995591 s

4 it number
learning rate: 7.8e-04
num_dense_layers: 8
num_dense_nodes: 54
activation: sigmoid

Compiling model...
'compile' took 0.016410 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.45e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [4.91e+03]    [7.08e+03]    [9.97e-01]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
6000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
7000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
8000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
9000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
10000     [5.21e+03]    [6.44e+03]    [1.00e+00]    

Best model at step 3000:
  train loss: 4.91e+03
  test loss: 7.08e+03
  test metric: [9.97e-01]

'train' took 156.422587 s

5 it number
learning rate: 1.6e-03
num_dense_layers: 1
num_dense_nodes: 149
activation: sigmoid

Compiling model...
'compile' took 0.000099 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.45e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.18e+03]    [6.41e+03]    [9.98e-01]    
6000      [5.14e+03]    [6.33e+03]    [9.91e-01]    
7000      [4.77e+03]    [5.84e+03]    [9.66e-01]    
8000      [3.55e+03]    [4.32e+03]    [9.44e-01]    
9000      [1.93e+03]    [2.28e+03]    [1.01e+00]    
10000     [1.25e+03]    [1.43e+03]    [1.07e+00]    

Best model at step 10000:
  train loss: 1.25e+03
  test loss: 1.43e+03
  test metric: [1.07e+00]

'train' took 66.855548 s

6 it number
learning rate: 9.8e-03
num_dense_layers: 9
num_dense_nodes: 494
activation: sigmoid

Compiling model...
'compile' took 0.000134 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
6000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
7000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
8000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
9000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
10000     [5.21e+03]    [6.44e+03]    [1.00e+00]    

Best model at step 1000:
  train loss: 5.21e+03
  test loss: 6.44e+03
  test metric: [1.00e+00]

'train' took 167.971275 s

7 it number
learning rate: 1.2e-03
num_dense_layers: 5
num_dense_nodes: 271
activation: tanh

Compiling model...
'compile' took 0.000114 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.30e+03]    [1.00e+04]    [1.01e+00]    
2000      [7.06e+02]    [1.02e+04]    [9.89e-01]    
3000      [1.24e+03]    [8.28e+03]    [9.98e-01]    
4000      [3.28e+02]    [9.36e+03]    [1.06e+00]    
5000      [2.56e+03]    [8.06e+03]    [9.37e-01]    
6000      [1.02e+03]    [1.03e+04]    [9.67e-01]    
7000      [4.89e+02]    [1.13e+04]    [9.69e-01]    
8000      [3.29e+03]    [7.69e+03]    [9.62e-01]    
9000      [1.56e+03]    [1.10e+04]    [9.71e-01]    
10000     [4.88e+02]    [1.40e+04]    [9.98e-01]    

Best model at step 4000:
  train loss: 3.28e+02
  test loss: 9.36e+03
  test metric: [1.06e+00]

'train' took 117.106942 s

8 it number
learning rate: 1.8e-03
num_dense_layers: 5
num_dense_nodes: 287
activation: tanh

Compiling model...
'compile' took 0.000116 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.26e+03]    [6.68e+03]    [1.02e+00]    
2000      [4.00e+03]    [6.22e+03]    [9.61e-01]    
3000      [3.87e+02]    [8.58e+03]    [9.53e-01]    
4000      [2.11e+03]    [7.06e+03]    [9.37e-01]    
5000      [7.17e+01]    [1.10e+04]    [9.31e-01]    
6000      [1.55e+03]    [7.77e+03]    [9.18e-01]    
7000      [9.12e+02]    [8.73e+03]    [9.60e-01]    
8000      [2.60e+02]    [9.99e+03]    [9.89e-01]    
9000      [8.04e+00]    [1.05e+04]    [1.01e+00]    
10000     [5.17e+03]    [6.38e+03]    [9.95e-01]    

Best model at step 9000:
  train loss: 8.04e+00
  test loss: 1.05e+04
  test metric: [1.01e+00]

'train' took 114.667106 s

9 it number
learning rate: 1.3e-04
num_dense_layers: 6
num_dense_nodes: 234
activation: sin

Compiling model...
'compile' took 0.000118 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [2.18e+02]    [3.25e+03]    [6.76e-01]    
2000      [2.97e+01]    [3.78e+03]    [8.11e-01]    
3000      [5.57e+00]    [3.88e+03]    [9.01e-01]    
4000      [1.13e+00]    [3.62e+03]    [9.35e-01]    
5000      [1.44e+00]    [3.31e+03]    [9.41e-01]    
6000      [2.83e-01]    [3.14e+03]    [9.45e-01]    
7000      [3.88e-01]    [2.61e+03]    [9.12e-01]    
8000      [1.92e-01]    [2.76e+03]    [9.33e-01]    
9000      [1.60e-01]    [2.67e+03]    [9.32e-01]    
10000     [3.24e-01]    [2.26e+03]    [9.02e-01]    

Best model at step 9000:
  train loss: 1.60e-01
  test loss: 2.67e+03
  test metric: [9.32e-01]

'train' took 131.488719 s

10 it number
learning rate: 7.7e-04
num_dense_layers: 8
num_dense_nodes: 325
activation: sigmoid

Compiling model...
'compile' took 0.000129 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.22e+03]    [6.45e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
6000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
7000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
8000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
9000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
10000     [5.21e+03]    [6.44e+03]    [1.00e+00]    

Best model at step 1000:
  train loss: 5.21e+03
  test loss: 6.44e+03
  test metric: [1.00e+00]

'train' took 159.348527 s

11 it number
learning rate: 1.4e-02
num_dense_layers: 4
num_dense_nodes: 120
activation: sin

Compiling model...
'compile' took 0.000154 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [4.95e+03]    [6.71e+03]    [9.95e-01]    
2000      [1.75e+03]    [2.51e+03]    [6.84e-01]    
3000      [7.58e+02]    [3.01e+04]    [1.00e+00]    
4000      [3.28e+01]    [6.54e+04]    [1.00e+00]    
5000      [7.05e+00]    [7.18e+04]    [1.00e+00]    
6000      [4.35e+00]    [7.10e+04]    [1.00e+00]    
7000      [1.22e+01]    [5.91e+04]    [1.00e+00]    
8000      [2.73e+01]    [3.99e+04]    [1.00e+00]    
9000      [2.55e+02]    [7.25e+04]    [1.00e+00]    
10000     [2.63e+01]    [1.05e+05]    [1.00e+00]    

Best model at step 6000:
  train loss: 4.35e+00
  test loss: 7.10e+04
  test metric: [1.00e+00]

'train' took 105.861927 s

12 it number
learning rate: 3.4e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000114 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [4.33e+03]    [5.34e+03]    [9.07e-01]    
2000      [9.81e+00]    [1.23e+01]    [1.26e-01]    
3000      [8.41e-01]    [1.14e+00]    [3.13e-02]    
4000      [2.89e-01]    [3.73e-01]    [9.91e-03]    
5000      [2.85e-01]    [3.47e-01]    [6.47e-03]    
6000      [8.04e-02]    [1.05e-01]    [4.07e-03]    
7000      [2.64e+00]    [2.83e+00]    [2.49e-02]    
8000      [4.60e-02]    [6.24e-02]    [2.53e-03]    
9000      [4.14e-02]    [5.61e-02]    [2.36e-03]    
10000     [1.84e+00]    [2.05e+00]    [2.06e-02]    

Best model at step 9000:
  train loss: 4.14e-02
  test loss: 5.61e-02
  test metric: [2.36e-03]

'train' took 105.394644 s

13 it number
learning rate: 5.0e-02
num_dense_layers: 1
num_dense_nodes: 5
activation: sigmoid

Compiling model...
'compile' took 0.000097 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [3.76e+03]    [4.51e+03]    [1.00e+00]    
2000      [3.69e+03]    [4.33e+03]    [1.06e+00]    
3000      [3.69e+03]    [4.31e+03]    [1.07e+00]    
4000      [3.69e+03]    [4.30e+03]    [1.07e+00]    
5000      [3.69e+03]    [4.30e+03]    [1.07e+00]    
6000      [3.69e+03]    [4.30e+03]    [1.07e+00]    
7000      [3.69e+03]    [4.30e+03]    [1.07e+00]    
8000      [3.69e+03]    [4.30e+03]    [1.07e+00]    
9000      [3.69e+03]    [4.30e+03]    [1.07e+00]    
10000     [3.69e+03]    [4.30e+03]    [1.07e+00]    

Best model at step 9000:
  train loss: 3.69e+03
  test loss: 4.30e+03
  test metric: [1.07e+00]

'train' took 66.824480 s

14 it number
learning rate: 1.0e-04
num_dense_layers: 1
num_dense_nodes: 500
activation: sigmoid

Compiling model...
'compile' took 0.000083 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.22e+03]    [6.45e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
6000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
7000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
8000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
9000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
10000     [5.21e+03]    [6.44e+03]    [1.00e+00]    

Best model at step 2000:
  train loss: 5.21e+03
  test loss: 6.44e+03
  test metric: [1.00e+00]

'train' took 67.073147 s

15 it number
learning rate: 4.4e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000111 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [1.02e+01]    [1.23e+01]    [1.07e-01]    
3000      [1.22e+00]    [1.53e+00]    [2.60e-02]    
4000      [8.89e-01]    [1.08e+00]    [1.50e-02]    
5000      [8.75e+00]    [1.08e+01]    [4.66e-02]    
6000      [3.20e-01]    [4.14e-01]    [8.14e-03]    
7000      [1.45e+00]    [1.78e+00]    [1.88e-02]    
8000      [1.19e-01]    [1.64e-01]    [3.94e-03]    
9000      [4.89e-01]    [5.56e-01]    [9.71e-03]    
10000     [2.27e-01]    [2.86e-01]    [5.39e-03]    

Best model at step 8000:
  train loss: 1.19e-01
  test loss: 1.64e-01
  test metric: [3.94e-03]

'train' took 105.342736 s

16 it number
learning rate: 4.8e-04
num_dense_layers: 5
num_dense_nodes: 5
activation: sin

Compiling model...
'compile' took 0.000124 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [4.96e+03]    [6.13e+03]    [9.71e-01]    
2000      [3.91e+03]    [4.72e+03]    [8.53e-01]    
3000      [3.35e+03]    [4.77e+03]    [8.51e-01]    
4000      [3.16e+03]    [4.68e+03]    [8.61e-01]    
5000      [3.02e+03]    [4.63e+03]    [8.76e-01]    
6000      [2.91e+03]    [4.53e+03]    [8.77e-01]    
7000      [2.76e+03]    [4.47e+03]    [8.66e-01]    
8000      [2.57e+03]    [4.43e+03]    [8.52e-01]    
9000      [2.23e+03]    [4.35e+03]    [8.53e-01]    
10000     [1.96e+03]    [4.27e+03]    [8.49e-01]    

Best model at step 10000:
  train loss: 1.96e+03
  test loss: 4.27e+03
  test metric: [8.49e-01]

'train' took 117.680881 s

17 it number
learning rate: 3.9e-04
num_dense_layers: 4
num_dense_nodes: 140
activation: sin

Compiling model...
'compile' took 0.000112 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [2.11e+02]    [3.08e+02]    [5.70e-01]    
2000      [4.77e+01]    [2.24e+03]    [6.12e-01]    
3000      [1.72e+01]    [4.90e+03]    [7.23e-01]    
4000      [8.66e+00]    [5.87e+03]    [7.66e-01]    
5000      [2.39e+00]    [6.33e+03]    [7.80e-01]    
6000      [1.69e+01]    [5.72e+03]    [7.86e-01]    
7000      [1.12e+00]    [5.71e+03]    [7.83e-01]    
8000      [5.83e+01]    [5.46e+03]    [7.83e-01]    
9000      [1.38e+00]    [5.22e+03]    [7.77e-01]    
10000     [3.75e+00]    [4.74e+03]    [7.70e-01]    

Best model at step 7000:
  train loss: 1.12e+00
  test loss: 5.71e+03
  test metric: [7.83e-01]

'train' took 105.677897 s

18 it number
learning rate: 5.3e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000113 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [2.60e+01]    [3.13e+01]    [1.92e-01]    
3000      [1.44e+00]    [1.82e+00]    [3.41e-02]    
4000      [2.46e+00]    [2.46e+00]    [2.22e-02]    
5000      [1.84e-01]    [2.63e-01]    [7.48e-03]    
6000      [6.40e+00]    [6.31e+00]    [6.08e-02]    
7000      [1.15e-01]    [1.73e-01]    [6.47e-03]    
8000      [5.87e-01]    [6.81e-01]    [1.31e-02]    
9000      [1.61e-01]    [2.07e-01]    [6.39e-03]    
10000     [3.01e-01]    [3.32e-01]    [8.63e-03]    

Best model at step 7000:
  train loss: 1.15e-01
  test loss: 1.73e-01
  test metric: [6.47e-03]

'train' took 105.358877 s

19 it number
learning rate: 5.0e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sigmoid

Compiling model...
'compile' took 0.000111 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.25e+03]    [6.49e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
3000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
4000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
5000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
6000      [2.76e+03]    [4.95e+03]    [9.80e-01]    
7000      [2.02e+03]    [5.85e+03]    [9.63e-01]    
8000      [1.60e+03]    [6.21e+03]    [1.02e+00]    
9000      [1.51e+03]    [6.92e+03]    [1.11e+00]    
10000     [8.82e+02]    [6.42e+03]    [1.16e+00]    

Best model at step 10000:
  train loss: 8.82e+02
  test loss: 6.42e+03
  test metric: [1.16e+00]

'train' took 105.634210 s

20 it number
learning rate: 5.0e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000111 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [7.39e+00]    [8.19e+00]    [7.76e-02]    
3000      [8.25e-01]    [9.46e-01]    [1.25e-02]    
4000      [1.64e+00]    [1.86e+00]    [1.56e-02]    
5000      [2.99e+00]    [3.36e+00]    [2.56e-02]    
6000      [1.04e-01]    [1.30e-01]    [2.19e-03]    
7000      [1.26e-01]    [1.44e-01]    [3.66e-03]    
8000      [9.89e-02]    [1.30e-01]    [2.84e-03]    
9000      [2.27e+00]    [2.53e+00]    [2.20e-02]    
10000     [6.72e+00]    [7.08e+00]    [3.91e-02]    

Best model at step 8000:
  train loss: 9.89e-02
  test loss: 1.30e-01
  test metric: [2.84e-03]

'train' took 104.931757 s

21 it number
learning rate: 4.9e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000106 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [3.75e+03]    [4.50e+03]    [8.52e-01]    
3000      [2.21e+00]    [2.47e+00]    [2.43e-02]    
4000      [3.17e+00]    [3.40e+00]    [2.27e-02]    
5000      [2.30e-01]    [2.36e-01]    [6.80e-03]    
6000      [2.52e-01]    [2.40e-01]    [6.63e-03]    
7000      [8.18e-01]    [9.06e-01]    [1.35e-02]    
8000      [7.30e-02]    [8.01e-02]    [3.31e-03]    
9000      [1.29e-01]    [1.45e-01]    [4.30e-03]    
10000     [3.31e+00]    [3.57e+00]    [2.48e-02]    

Best model at step 8000:
  train loss: 7.30e-02
  test loss: 8.01e-02
  test metric: [3.31e-03]

'train' took 104.905972 s

22 it number
learning rate: 4.7e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000113 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.02e+02]    [1.28e+02]    [4.44e-01]    
2000      [7.54e+00]    [1.13e+01]    [1.13e-01]    
3000      [7.22e-01]    [1.41e+00]    [3.11e-02]    
4000      [4.20e-01]    [7.05e-01]    [1.49e-02]    
5000      [3.46e-01]    [5.36e-01]    [1.09e-02]    
6000      [2.54e+00]    [2.79e+00]    [1.97e-02]    
7000      [6.92e-01]    [8.45e-01]    [1.18e-02]    
8000      [1.94e-02]    [1.05e-01]    [1.78e-03]    
9000      [8.04e-01]    [1.02e+00]    [1.19e-02]    
10000     [9.07e-02]    [1.72e-01]    [4.13e-03]    

Best model at step 8000:
  train loss: 1.94e-02
  test loss: 1.05e-01
  test metric: [1.78e-03]

'train' took 104.927081 s

23 it number
learning rate: 4.5e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000122 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [6.24e+00]    [7.43e+00]    [7.20e-02]    
3000      [1.92e+00]    [2.06e+00]    [3.71e-02]    
4000      [6.39e-01]    [6.94e-01]    [2.00e-02]    
5000      [9.76e+00]    [1.18e+01]    [4.92e-02]    
6000      [5.35e+00]    [5.81e+00]    [3.34e-02]    
7000      [1.90e-01]    [2.59e-01]    [8.56e-03]    
8000      [4.40e+00]    [4.89e+00]    [3.02e-02]    
9000      [7.22e-01]    [8.25e-01]    [1.15e-02]    
10000     [5.16e-01]    [5.75e-01]    [1.09e-02]    

Best model at step 7000:
  train loss: 1.90e-01
  test loss: 2.59e-01
  test metric: [8.56e-03]

'train' took 104.922173 s

24 it number
learning rate: 2.7e-02
num_dense_layers: 6
num_dense_nodes: 380
activation: sin

Compiling model...
'compile' took 0.000123 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.94e+15]    [4.07e+20]    [1.01e+00]    
2000      [2.33e+16]    [4.17e+20]    [1.01e+00]    
3000      [4.51e+14]    [4.21e+20]    [1.01e+00]    
4000      [8.89e+16]    [4.24e+20]    [1.01e+00]    
5000      [7.73e+15]    [3.95e+21]    [1.01e+00]    
6000      [1.34e+16]    [3.96e+21]    [1.01e+00]    
7000      [5.89e+14]    [3.95e+21]    [1.01e+00]    
8000      [1.80e+14]    [3.96e+21]    [1.01e+00]    
9000      [3.23e+15]    [3.97e+21]    [1.01e+00]    
10000     [2.00e+18]    [3.98e+21]    [1.01e+00]    

Best model at step 0:
  train loss: 5.21e+03
  test loss: 6.44e+03
  test metric: [1.00e+00]

'train' took 132.583855 s

25 it number
learning rate: 4.5e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000114 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [1.87e+01]    [2.52e+01]    [1.63e-01]    
3000      [1.36e+00]    [2.27e+00]    [4.55e-02]    
4000      [1.98e-01]    [4.20e-01]    [1.64e-02]    
5000      [2.94e+00]    [3.69e+00]    [2.35e-02]    
6000      [4.35e-01]    [5.97e-01]    [8.86e-03]    
7000      [1.52e-01]    [2.56e-01]    [6.18e-03]    
8000      [1.10e-01]    [1.84e-01]    [3.56e-03]    
9000      [2.20e-02]    [8.16e-02]    [1.87e-03]    
10000     [6.15e+00]    [6.87e+00]    [3.63e-02]    

Best model at step 9000:
  train loss: 2.20e-02
  test loss: 8.16e-02
  test metric: [1.87e-03]

'train' took 104.927077 s

26 it number
learning rate: 5.4e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000113 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.03e+03]    [6.22e+03]    [9.83e-01]    
2000      [2.01e+00]    [2.36e+00]    [5.40e-02]    
3000      [1.71e-01]    [1.92e-01]    [9.37e-03]    
4000      [1.21e-01]    [1.37e-01]    [5.36e-03]    
5000      [1.71e+00]    [1.93e+00]    [2.04e-02]    
6000      [2.41e-01]    [2.72e-01]    [6.53e-03]    
7000      [1.22e-01]    [1.38e-01]    [4.99e-03]    
8000      [4.54e-01]    [4.81e-01]    [7.93e-03]    
9000      [1.82e+00]    [1.97e+00]    [2.00e-02]    
10000     [3.39e-01]    [3.71e-01]    [8.50e-03]    

Best model at step 4000:
  train loss: 1.21e-01
  test loss: 1.37e-01
  test metric: [5.36e-03]

'train' took 104.924940 s

27 it number
learning rate: 5.6e-04
num_dense_layers: 3
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000106 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.12e+03]    [6.33e+03]    [9.91e-01]    
2000      [8.12e-01]    [9.08e-01]    [3.15e-02]    
3000      [8.42e-02]    [9.10e-02]    [3.53e-03]    
4000      [3.40e-02]    [3.55e-02]    [1.95e-03]    
5000      [1.58e-01]    [1.82e-01]    [5.50e-03]    
6000      [7.44e-02]    [8.02e-02]    [4.59e-03]    
7000      [1.05e-01]    [1.12e-01]    [4.93e-03]    
8000      [1.85e-01]    [2.00e-01]    [6.40e-03]    
9000      [8.06e-03]    [8.43e-03]    [7.98e-04]    
10000     [1.03e+00]    [1.13e+00]    [1.53e-02]    

Best model at step 9000:
  train loss: 8.06e-03
  test loss: 8.43e-03
  test metric: [7.98e-04]

'train' took 92.482032 s

28 it number
learning rate: 7.3e-04
num_dense_layers: 4
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000112 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [5.21e+03]    [6.44e+03]    [1.00e+00]    
2000      [1.86e+01]    [2.18e+01]    [8.71e-02]    
3000      [1.41e+00]    [1.60e+00]    [1.99e-02]    
4000      [1.03e+01]    [1.16e+01]    [4.36e-02]    
5000      [9.44e+00]    [1.00e+01]    [3.73e-02]    
6000      [5.41e+00]    [5.92e+00]    [3.07e-02]    
7000      [9.79e-02]    [1.09e-01]    [4.28e-03]    
8000      [2.37e-01]    [2.60e-01]    [4.55e-03]    
9000      [3.11e-01]    [3.28e-01]    [8.51e-03]    
10000     [5.25e-01]    [6.05e-01]    [9.55e-03]    

Best model at step 7000:
  train loss: 9.79e-02
  test loss: 1.09e-01
  test metric: [4.28e-03]

'train' took 104.920863 s

29 it number
learning rate: 1.0e-04
num_dense_layers: 8
num_dense_nodes: 500
activation: sin

Compiling model...
'compile' took 0.000123 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.57e+02]    [1.98e+02]    [5.31e-01]    
2000      [8.39e+01]    [2.04e+02]    [4.58e-01]    
3000      [1.96e+01]    [7.92e+02]    [5.61e-01]    
4000      [6.58e+00]    [1.24e+03]    [6.07e-01]    
5000      [3.09e+00]    [1.32e+03]    [6.18e-01]    
6000      [8.13e-01]    [1.41e+03]    [6.29e-01]    
7000      [1.11e+01]    [9.85e+02]    [5.61e-01]    
8000      [2.58e+01]    [1.29e+03]    [6.04e-01]    
9000      [1.50e+01]    [1.24e+03]    [5.96e-01]    
10000     [2.25e+00]    [7.17e+02]    [4.71e-01]    

Best model at step 6000:
  train loss: 8.13e-01
  test loss: 1.41e+03
  test metric: [6.29e-01]

'train' took 154.004872 s

30 it number
learning rate: 8.3e-03
num_dense_layers: 3
num_dense_nodes: 421
activation: sin

Compiling model...
'compile' took 0.000109 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [1.41e+03]    [1.57e+04]    [1.00e+00]    
2000      [1.69e+01]    [2.39e+04]    [1.00e+00]    
3000      [1.85e+01]    [2.12e+04]    [1.00e+00]    
4000      [3.40e+00]    [1.82e+04]    [1.00e+00]    
5000      [6.15e+00]    [1.44e+04]    [9.99e-01]    
6000      [1.82e+01]    [1.38e+04]    [9.99e-01]    
7000      [6.45e+01]    [4.77e+03]    [7.42e-01]    
8000      [2.10e+00]    [3.79e+03]    [7.59e-01]    
9000      [8.80e+01]    [6.43e+02]    [6.29e-01]    
10000     [2.36e+03]    [8.86e+03]    [9.58e-01]    

Best model at step 8000:
  train loss: 2.10e+00
  test loss: 3.79e+03
  test metric: [7.59e-01]

'train' took 94.563256 s

31 it number
learning rate: 2.8e-04
num_dense_layers: 3
num_dense_nodes: 459
activation: sin

Compiling model...
'compile' took 0.000108 s

Training model...

Step      Train loss    Test loss     Test metric   
0         [5.21e+03]    [6.44e+03]    [1.00e+00]    
1000      [3.90e+03]    [4.75e+03]    [8.61e-01]    
2000      [5.21e+00]    [6.05e+00]    [8.58e-02]    
3000      [2.39e-01]    [2.62e-01]    [8.96e-03]    
4000      [1.09e-01]    [1.20e-01]    [4.11e-03]    
